{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "569b436f",
   "metadata": {},
   "source": [
    "# STEP1 -- LOAD A PDF FILE AND FETCH DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1005a042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting text extraction from Sample_PDF.pdf using PyPDFLoader...\n",
      "Loaded PDF: Sample_PDF.pdf with 249 pages using PyPDFLoader.\n",
      "Processed page 50/249...\n",
      "Processed page 100/249...\n",
      "Processed page 150/249...\n",
      "Processed page 200/249...\n",
      "Processed page 249/249...\n",
      "Text extraction complete. Total pages processed: 249\n",
      "Extracted text saved to: pmis_extracted_text.txt\n",
      "\n",
      "Step 1 (PDF Data Fetch) completed successfully using PyPDFLoader!\n",
      "You can now find the extracted text in 'pmis_extracted_text.txt'.\n"
     ]
    }
   ],
   "source": [
    "# https://ftp.dot.state.tx.us/pub/txdot-info/cst/pmis2004.pdf\n",
    "\n",
    "import os, requests\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "PDF_URL = \"https://ftp.dot.state.tx.us/pub/txdot-info/cst/pmis2004.pdf\"\n",
    "PDF_FILENAME = \"Sample_PDF.pdf\"\n",
    "OUTPUT_TEXT_FILENAME = \"pmis_extracted_text.txt\"\n",
    "\n",
    "def download_pdf(url, filename):\n",
    "    print(f\"Attempting to download PDF from: {url}\")\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "        with open(filename, 'wb') as pdf_file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                pdf_file.write(chunk)\n",
    "        print(f\"Successfully downloaded {filename}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading PDF: {e}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def extract_text_from_pdf_with_pypdfloader(pdf_path, output_path):\n",
    "    full_text_content = []\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        # load_and_split() splits by page by default\n",
    "        # If you wanted to do other splits, you'd use load() and then a text splitter\n",
    "        documents = loader.load_and_split()\n",
    "\n",
    "        num_pages = len(documents)\n",
    "        print(f\"Loaded PDF: {pdf_path} with {num_pages} pages using PyPDFLoader.\")\n",
    "\n",
    "        if num_pages < 200:\n",
    "            print(f\"Warning: PDF has {num_pages} pages, which is less than the recommended 200 pages.\")\n",
    "            print(\"Consider using a larger PDF for better demonstration of chunking and indexing.\")\n",
    "\n",
    "        for i, doc in enumerate(documents):\n",
    "            full_text_content.append(doc.page_content)\n",
    "            if (i + 1) % 50 == 0 or (i + 1) == num_pages:\n",
    "                print(f\"Processed page {i + 1}/{num_pages}...\")\n",
    "\n",
    "        # Save the extracted text to a file\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(full_text_content))\n",
    "\n",
    "        print(f\"Text extraction complete. Total pages processed: {num_pages}\")\n",
    "        print(f\"Extracted text saved to: {output_path}\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: PDF file not found at {pdf_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during PDF text extraction with PyPDFLoader: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import requests\n",
    "        from langchain_community.document_loaders import PyPDFLoader\n",
    "    except ImportError as e:\n",
    "        print(f\"Missing required library: {e}. Please install using:\")\n",
    "        print(\"pip install requests langchain-community pypdf\")\n",
    "        exit()\n",
    "\n",
    "    if not os.path.exists(PDF_FILENAME):\n",
    "        print(f\"PDF file '{PDF_FILENAME}' not found locally. Attempting to download...\")\n",
    "        if not download_pdf(PDF_URL, PDF_FILENAME):\n",
    "            print(f\"Please ensure you have a large PDF file named {PDF_FILENAME} in the same directory.\")\n",
    "            exit()\n",
    "\n",
    "    # Extract text from the downloaded/existing PDF using PyPDFLoader\n",
    "    print(f\"\\nStarting text extraction from {PDF_FILENAME} using PyPDFLoader...\")\n",
    "    if extract_text_from_pdf_with_pypdfloader(PDF_FILENAME, OUTPUT_TEXT_FILENAME):\n",
    "        print(\"\\nStep 1 (PDF Data Fetch) completed successfully using PyPDFLoader!\")\n",
    "        print(f\"You can now find the extracted text in '{OUTPUT_TEXT_FILENAME}'.\")\n",
    "    else:\n",
    "        print(\"\\nStep 1 (PDF Data Fetch) failed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad5b417",
   "metadata": {},
   "source": [
    "# STEP2 -- SEMANTIC CHUNKING AND EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af43d6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Semantic Chunking ---\n",
      "Starting chunking with chunk_size=1000, chunk_overlap=200\n",
      "Text chunking complete. Created 336 chunks.\n",
      "\n",
      "--- Starting Embedding Generation ---\n",
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/7c3ybrfx0fgd7fpsjfhl1qc40000gn/T/ipykernel_3535/3496575305.py:32: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={'device': 'cpu'})\n",
      "/Users/nitin/AgenticAI_Assignments/RAG_Assignment_1/RAGAssignment1/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded successfully.\n",
      "Generating embeddings for 336 chunks...\n",
      "Embeddings generation complete.\n",
      "\n",
      "Chunks and embeddings saved to 'chunks_with_embeddings.json' for inspection.\n",
      "\n",
      "Step 2 (Semantic Chunking and Embedding) completed successfully!\n",
      "You now have 336 chunks, each with its associated embedding.\n"
     ]
    }
   ],
   "source": [
    "import os, uuid, json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# --- Configuration (using constants from previous step's output) --- #\n",
    "\n",
    "OUTPUT_TEXT_FILENAME = \"pmis_extracted_text.txt\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "EMBEDDINGS_OUTPUT_FILE = \"chunks_with_embeddings.json\"\n",
    "\n",
    "def chunk_text(text_content: str) -> list[Document]:\n",
    "    print(f\"Starting chunking with chunk_size={CHUNK_SIZE}, chunk_overlap={CHUNK_OVERLAP}\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        length_function=len, \n",
    "        add_start_index=True,\n",
    "    )\n",
    "    # The splitter works on a list of strings, so wrap the single text content in a list\n",
    "    chunks = text_splitter.create_documents([text_content])\n",
    "    print(f\"Text chunking complete. Created {len(chunks)} chunks.\")\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def embed_chunks(chunks: list[Document], model_name: str) -> list[Document]:\n",
    "    print(f\"Loading embedding model: {model_name}\")\n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={'device': 'cpu'})\n",
    "        print(\"Embedding model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading embedding model: {e}\")\n",
    "        print(\"Please ensure 'sentence-transformers' library is installed: pip install sentence-transformers\")\n",
    "        print(\"Also check if the model name is correct and accessible.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Generating embeddings for {len(chunks)} chunks...\")\n",
    "    # Generate embeddings for each chunk's page_content\n",
    "    # The embeddings object's embed_documents method takes a list of strings\n",
    "    chunk_texts = [doc.page_content for doc in chunks]\n",
    "    chunk_embeddings = embeddings.embed_documents(chunk_texts)\n",
    "\n",
    "    for i, doc in enumerate(chunks):\n",
    "        doc.metadata[\"embedding\"] = chunk_embeddings[i]\n",
    "        doc.metadata[\"chunk_id\"] = str(uuid.uuid4())\n",
    "\n",
    "    print(\"Embeddings generation complete.\")\n",
    "    return chunks\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "        from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "        from langchain.docstore.document import Document\n",
    "        import json\n",
    "        import uuid\n",
    "    except ImportError as e:\n",
    "        print(f\"Missing required library: {e}. Please install using:\")\n",
    "        print(\"pip install langchain-text-splitters langchain-community sentence-transformers\")\n",
    "        exit()\n",
    "\n",
    "    if not os.path.exists(OUTPUT_TEXT_FILENAME):\n",
    "        print(f\"Error: Extracted text file '{OUTPUT_TEXT_FILENAME}' not found.\")\n",
    "        print(\"Please run the PDF extraction step first to create this file.\")\n",
    "        exit()\n",
    "\n",
    "    with open(OUTPUT_TEXT_FILENAME, 'r', encoding='utf-8') as f:\n",
    "        text_content = f.read()\n",
    "\n",
    "    # Perform semantic chunking\n",
    "    print(\"\\n--- Starting Semantic Chunking ---\")\n",
    "    processed_chunks = chunk_text(text_content)\n",
    "    if not processed_chunks:\n",
    "        print(\"Chunking failed. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Generate embeddings for the chunks\n",
    "    print(\"\\n--- Starting Embedding Generation ---\")\n",
    "    chunks_with_embeddings = embed_chunks(processed_chunks, EMBEDDING_MODEL_NAME)\n",
    "    if not chunks_with_embeddings:\n",
    "        print(\"Embedding generation failed. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Save chunks with embeddings (optional, but good for inspection/debugging)\n",
    "    # Saving them as a list of dictionaries.\n",
    "    serializable_data = []\n",
    "    for doc in chunks_with_embeddings:\n",
    "        serializable_data.append({\n",
    "            \"page_content\": doc.page_content,\n",
    "            \"metadata\": doc.metadata,\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        with open(EMBEDDINGS_OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(serializable_data, f, indent=2)\n",
    "        print(f\"\\nChunks and embeddings saved to '{EMBEDDINGS_OUTPUT_FILE}' for inspection.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving chunks with embeddings to file: {e}\")\n",
    "\n",
    "\n",
    "    print(\"\\nStep 2 (Semantic Chunking and Embedding) completed successfully!\")\n",
    "    print(f\"You now have {len(chunks_with_embeddings)} chunks, each with its associated embedding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ebb4f",
   "metadata": {},
   "source": [
    "# STEP 3 - MILVUS INDEX CREATION & DATA INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2dee65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitin/AgenticAI_Assignments/RAG_Assignment_1/RAGAssignment1/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to connect to Milvus at localhost:19530...\n",
      "Milvus connection successful!\n",
      "\n",
      "--- Creating Milvus Collections and Indexes ---\n",
      "\n",
      "Creating collection 'document_chunks_hnsw' with schema...\n",
      "Collection 'document_chunks_hnsw' created.\n",
      "Creating HNSW index on 'embedding' field for 'document_chunks_hnsw'...\n",
      "Index 'HNSW' created successfully on 'document_chunks_hnsw'.\n",
      "\n",
      "Creating collection 'document_chunks_ivf' with schema...\n",
      "Collection 'document_chunks_ivf' created.\n",
      "Creating IVF_FLAT index on 'embedding' field for 'document_chunks_ivf'...\n",
      "Index 'IVF_FLAT' created successfully on 'document_chunks_ivf'.\n",
      "\n",
      "Creating collection 'document_chunks_flat' with schema...\n",
      "Collection 'document_chunks_flat' created.\n",
      "Creating FLAT index on 'embedding' field for 'document_chunks_flat'...\n",
      "Index 'FLAT' created successfully on 'document_chunks_flat'.\n",
      "\n",
      "--- Loading Data from JSON ---\n",
      "Successfully loaded 336 chunk-embedding pairs from chunks_with_embeddings.json\n",
      "\n",
      "--- Ingesting Data into Milvus Collections ---\n",
      "Inserting 336 entities into collection 'document_chunks_hnsw'...\n",
      "Successfully inserted data into 'document_chunks_hnsw'. Insert count: 336\n",
      "Collection 'document_chunks_hnsw' flushed. Entity count: 336\n",
      "Error ensuring collection 'document_chunks_hnsw' is loaded: 'Collection' object has no attribute 'is_loaded'\n",
      "Inserting 336 entities into collection 'document_chunks_ivf'...\n",
      "Successfully inserted data into 'document_chunks_ivf'. Insert count: 336\n",
      "Collection 'document_chunks_ivf' flushed. Entity count: 336\n",
      "Error ensuring collection 'document_chunks_ivf' is loaded: 'Collection' object has no attribute 'is_loaded'\n",
      "Inserting 336 entities into collection 'document_chunks_flat'...\n",
      "Successfully inserted data into 'document_chunks_flat'. Insert count: 336\n",
      "Collection 'document_chunks_flat' flushed. Entity count: 336\n",
      "Error ensuring collection 'document_chunks_flat' is loaded: 'Collection' object has no attribute 'is_loaded'\n",
      "\n",
      "Step 3 (Milvus Indexing and Data Ingestion) completed successfully!\n",
      "Your document chunks and embeddings are now indexed in Milvus in collections:\n",
      "- 'document_chunks_hnsw'\n",
      "- 'document_chunks_ivf'\n",
      "- 'document_chunks_flat'\n",
      "\n",
      "Next, we will proceed with building the retrieval pipeline using Milvus for vector search (Step 4).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema, CollectionSchema, DataType,\n",
    "    Collection,\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# --- Configuration for Milvus Connection ---\n",
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\" \n",
    "\n",
    "COLLECTION_NAME = \"document_chunks\" \n",
    "VECTOR_DIMENSION = 384\n",
    "\n",
    "EMBEDDINGS_JSON_FILE_PATH = \"chunks_with_embeddings.json\"\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "embedding_model = None\n",
    "\n",
    "# Define the schema for our document chunks\n",
    "# We'll use a simple schema with a primary key, text content, and the embedding vector.\n",
    "# For a full RAG pipeline, you should also include source metadata.\n",
    "fields = [\n",
    "    FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"page_content\", dtype=DataType.VARCHAR, max_length=65535), # Store the text chunk\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=VECTOR_DIMENSION)\n",
    "]\n",
    "schema = CollectionSchema(fields, \"Document chunks for RAG demo\")\n",
    "\n",
    "\n",
    "# --- Index Parameters for HNSW and IVF ---\n",
    "# These parameters are crucial for how Milvus builds and searches the index.\n",
    "# HNSW parameters:\n",
    "#   M: Max number of outgoing connections for each node in the graph. Higher M means denser graph,\n",
    "#      better recall, but slower build/larger index. Common range 4-64.\n",
    "#   efConstruction: Controls the size of the dynamic list during graph construction.\n",
    "#                   Higher efConstruction means more accurate graph, but slower build.\n",
    "#                   Common range 100-500.\n",
    "HNSW_INDEX_PARAMS = {\n",
    "    \"metric_type\": \"COSINE\", # Use cosine similarity for text embeddings\n",
    "    \"index_type\": \"HNSW\",\n",
    "    \"params\": {\"M\": 16, \"efConstruction\": 200}\n",
    "}\n",
    "\n",
    "# IVF parameters:\n",
    "#   nlist: Number of clusters (quantizers). Higher nlist means smaller clusters,\n",
    "#          potentially faster search (fewer comparisons per cluster), but more clusters to manage.\n",
    "#          A common heuristic is sqrt(N) to 8*sqrt(N), where N is number of vectors.\n",
    "#          For our PDF, it's likely hundreds to low thousands of chunks, so 1024 is a reasonable start.\n",
    "#   nprobe: Number of clusters to search during query. Higher nprobe means better recall,\n",
    "#           but slower search. Should be <= nlist.\n",
    "IVF_INDEX_PARAMS = {\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"index_type\": \"IVF_FLAT\", # IVF_FLAT is a common IVF variant\n",
    "    \"params\": {\"nlist\": 1024}\n",
    "}\n",
    "\n",
    "# FLAT index parameters (brute-force search)\n",
    "FLAT_INDEX_PARAMS = {\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"index_type\": \"FLAT\", # No specific parameters for FLAT as it's a direct comparison\n",
    "    \"params\": {}\n",
    "}\n",
    "\n",
    "def connect_to_milvus():\n",
    "    try:\n",
    "        print(f\"Attempting to connect to Milvus at {MILVUS_HOST}:{MILVUS_PORT}...\")\n",
    "        connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "        utility.list_collections() # Verify connection\n",
    "        print(\"Milvus connection successful!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Milvus connection failed: {e}\")\n",
    "        print(\"Please ensure your Milvus Docker container is running (run 'docker ps').\")\n",
    "        return False\n",
    "\n",
    "def create_milvus_collection_with_index(collection_name_suffix: str, index_params: Dict[str, Any]) -> Collection:\n",
    "    full_collection_name = f\"{COLLECTION_NAME}_{collection_name_suffix}\"\n",
    "\n",
    "    if utility.has_collection(full_collection_name):\n",
    "        print(f\"\\nCollection '{full_collection_name}' already exists. Dropping and recreating...\")\n",
    "        utility.drop_collection(full_collection_name)\n",
    "\n",
    "    print(f\"\\nCreating collection '{full_collection_name}' with schema...\")\n",
    "    collection = Collection(full_collection_name, schema)\n",
    "    print(f\"Collection '{full_collection_name}' created.\")\n",
    "\n",
    "    # Create the index\n",
    "    print(f\"Creating {index_params['index_type']} index on 'embedding' field for '{full_collection_name}'...\")\n",
    "    index = {\n",
    "        \"field_name\": \"embedding\",\n",
    "        \"index_type\": index_params[\"index_type\"],\n",
    "        \"metric_type\": index_params[\"metric_type\"],\n",
    "        \"params\": index_params[\"params\"]\n",
    "    }\n",
    "    collection.create_index(\"embedding\", index_params=index)\n",
    "    print(f\"Index '{index_params['index_type']}' created successfully on '{full_collection_name}'.\")\n",
    "\n",
    "    return collection\n",
    "\n",
    "def load_chunks_and_embeddings_from_json(file_path: str) -> List[Dict[str, Any]]:\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        # Ensure we extract 'page_content' and 'embedding' from the loaded structure\n",
    "        # The 'semantic_chunking_embedding.py' script saves it with 'page_content' and 'metadata'\n",
    "        processed_data = [\n",
    "            {\"chunk\": entry[\"page_content\"], \"embedding\": entry[\"metadata\"][\"embedding\"]}\n",
    "            for entry in data\n",
    "        ]\n",
    "        print(f\"Successfully loaded {len(processed_data)} chunk-embedding pairs from {file_path}\")\n",
    "        return processed_data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: JSON file not found at {file_path}. Please ensure it exists and the path is correct.\")\n",
    "        return []\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON from {file_path}: {e}\")\n",
    "        return []\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Missing expected key in JSON data (e.g., 'page_content' or 'embedding' in 'metadata'). Check format. Error: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while loading JSON from {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def insert_data_into_milvus(collection: Collection, data_entries: List[Dict[str, Any]]):\n",
    "    if not collection:\n",
    "        print(f\"Skipping data insertion for {collection.name if collection else 'unknown'} collection due to missing object.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Inserting {len(data_entries)} entities into collection '{collection.name}'...\")\n",
    "\n",
    "    # Prepare data for insertion: Milvus requires data as columns\n",
    "    chunks = [entry[\"chunk\"] for entry in data_entries]\n",
    "    embeddings = [entry[\"embedding\"] for entry in data_entries]\n",
    "\n",
    "    data = [\n",
    "        chunks,      # corresponds to 'page_content' field in schema\n",
    "        embeddings   # corresponds to 'embedding' field in schema\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        insert_result = collection.insert(data)\n",
    "        print(f\"Successfully inserted data into '{collection.name}'. Insert count: {insert_result.insert_count}\")\n",
    "        # Always call flush() after inserts to ensure data is written and searchable\n",
    "        collection.flush()\n",
    "        # Refresh collection info to get updated entity count\n",
    "        collection.load() # Load collection to query num_entities\n",
    "        print(f\"Collection '{collection.name}' flushed. Entity count: {collection.num_entities}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into '{collection.name}': {e}\")\n",
    "    finally:\n",
    "        # Ensure collection is loaded after insertion for immediate searchability\n",
    "        try:\n",
    "            if not collection.is_loaded:\n",
    "                collection.load()\n",
    "                print(f\"Collection '{collection.name}' loaded into memory.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error ensuring collection '{collection.name}' is loaded: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import pymilvus\n",
    "        import json\n",
    "        # SentenceTransformer is imported but not actively used for generation in this script,\n",
    "        # but kept for consistency and future retrieval steps that use this model.\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "    except ImportError as e:\n",
    "        print(f\"Missing required library: {e}. Please install using:\")\n",
    "        print(\"pip install pymilvus sentence-transformers\")\n",
    "        exit()\n",
    "\n",
    "    # Connect to Milvus\n",
    "    if not connect_to_milvus():\n",
    "        exit()\n",
    "\n",
    "    # Create Milvus Collections with Indexes\n",
    "    print(\"\\n--- Creating Milvus Collections and Indexes ---\")\n",
    "    hnsw_collection = create_milvus_collection_with_index(\"hnsw\", HNSW_INDEX_PARAMS)\n",
    "    ivf_collection = create_milvus_collection_with_index(\"ivf\", IVF_INDEX_PARAMS)\n",
    "    flat_collection = create_milvus_collection_with_index(\"flat\", FLAT_INDEX_PARAMS) # For learning/comparison\n",
    "\n",
    "    if not all([hnsw_collection, ivf_collection, flat_collection]):\n",
    "        print(\"One or more Milvus collections could not be created. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Load chunks and embeddings from JSON\n",
    "    print(\"\\n--- Loading Data from JSON ---\")\n",
    "    document_data = load_chunks_and_embeddings_from_json(EMBEDDINGS_JSON_FILE_PATH)\n",
    "    if not document_data:\n",
    "        print(\"No document data loaded. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Ingest Data into all created Milvus Collections\n",
    "    print(\"\\n--- Ingesting Data into Milvus Collections ---\")\n",
    "    insert_data_into_milvus(hnsw_collection, document_data)\n",
    "    insert_data_into_milvus(ivf_collection, document_data)\n",
    "    insert_data_into_milvus(flat_collection, document_data)\n",
    "\n",
    "    print(\"\\nStep 3 (Milvus Indexing and Data Ingestion) completed successfully!\")\n",
    "    print(f\"Your document chunks and embeddings are now indexed in Milvus in collections:\")\n",
    "    print(f\"- '{COLLECTION_NAME}_hnsw'\")\n",
    "    print(f\"- '{COLLECTION_NAME}_ivf'\")\n",
    "    print(f\"- '{COLLECTION_NAME}_flat'\")\n",
    "    print(\"\\nNext, we will proceed with building the retrieval pipeline using Milvus for vector search (Step 4).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b2dda",
   "metadata": {},
   "source": [
    "# STEP 4 -- MILVUS RETRIEVAL PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71dc0c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to connect to Milvus at localhost:19530...\n",
      "Milvus connection successful!\n",
      "\n",
      "--- Retrieving Milvus Collections ---\n",
      "Loading collection 'document_chunks_hnsw' into memory for search...\n",
      "Collection 'document_chunks_hnsw' loaded.\n",
      "Loading collection 'document_chunks_ivf' into memory for search...\n",
      "Collection 'document_chunks_ivf' loaded.\n",
      "Loading collection 'document_chunks_flat' into memory for search...\n",
      "Collection 'document_chunks_flat' loaded.\n",
      "Attempting to load model from or download to: /Users/nitin/AgenticAI_Assignments/RAG_Assignment_1/downloaded_embedding_model/all-MiniLM-L6-v2\n",
      "Model files not found or incomplete in '/Users/nitin/AgenticAI_Assignments/RAG_Assignment_1/downloaded_embedding_model/all-MiniLM-L6-v2'. Initiating robust download...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully downloaded to: /Users/nitin/AgenticAI_Assignments/RAG_Assignment_1/downloaded_embedding_model/all-MiniLM-L6-v2\n",
      "Embedding model loaded successfully from local path.\n",
      "\n",
      "--- Starting Interactive Retrieval ---\n",
      "Enter 'exit' to quit.\n",
      "\n",
      "--- Search Results (HNSW Index) ---\n",
      "\n",
      "Embedding query: 'How are the condition of roads in general ?'...\n",
      "Searching collection 'document_chunks_hnsw' with top_k=5...\n",
      "Retrieved 5 relevant chunks from 'document_chunks_hnsw'.\n",
      "HNSW Result 1 (Distance: 0.5817):\n",
      "  person’s perception of pavement quality. \n",
      "The overall condition of Texas pavements got slightly worse in FY 2007 mainly because of \n",
      "increased distress on asphalt pavements.  Overall pavement distress got worse, but overall ride \n",
      "quality improved.  A prolonged drought that began in mid-FY 2005 and lasted through all of FY \n",
      "2006, rising material costs, increased competition for limited construction materials, and \n",
      "increased oilfield development traffic contributed to the decline in statewide pavement condition. \n",
      "Although overall pavement condition declined, the statewide pavement condition goal \n",
      "percentage of lane miles in “Good” or better condition increased from 86.69 percent in FY 2006 \n",
      "to 86.76 percent in FY 2007.   \n",
      "Pavement condition and distress trends were mixed, but ride quality improved for each of the \n",
      "four major highway systems (IH, US, SH, and FM) in FY 2007.  IH and SH routes improved in\n",
      "HNSW Result 2 (Distance: 0.5593):\n",
      "  increased oilfield development traffic contributed to the decline in statewide pavement condition. \n",
      "Pavement condition and distress trends were mixed, but ride quality improved for each of the \n",
      "four major highway systems (IH, US, SH, and FM) in FY 2007.  IH and SH routes improved in \n",
      "all categories – condition, distress, ride, and “deep” distress.  US highways improved in distress, \n",
      "“deep” distress, and ride, but the improvements were all very small, and were not enough to keep \n",
      "the overall condition from getting worse.  FM roads improved in ride quality, but got worse in \n",
      "condition, distress, and “deep” distress. \n",
      "ACP condition and distress got worse, but ride quality improved in FY 2007.  “Deep” distress on \n",
      "improved because of a large reduction in Alligator Cracking.  ACP had the best overall condition \n",
      "and ride quality of the three major pavement types in FY 2007.  Shallow Rutting, Deep Rutting,\n",
      "HNSW Result 3 (Distance: 0.5587):\n",
      "  ♦ Data analyzed in this report was obtained from all PMIS sections, mainlane roadbeds, \n",
      "Condition Scores greater than 0, excluding sections under construction.  This analysis \n",
      "was consistent for the entire report except for the following portions of Chapter 7: \n",
      "♦ UTP Category 1 pages were based on all PMIS sections, mainlanes and frontage roads, \n",
      "Distress Score or Ride Score greater than 0 (where applicable), excluding sections under \n",
      "construction. \n",
      "♦ FHWA NHS ride quality tables were based on NHS sections, mainlanes only, with IRI \n",
      "left and right wheelpath greater than 0. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Cover Photo: \n",
      "IH 35 in Temple, Waco District \n",
      "Photo by Stan Williams, TxDOT.\n",
      "Condition of Texas Pavements, FY 2004-2007  i \n",
      " \n",
      "Executive Summary \n",
      "This report describes the condition of Texas pavements in Fiscal Year 2007 and during the four-\n",
      "year FY 2004-2007 period, based on analysis of Pavement Management Information System\n",
      "HNSW Result 4 (Distance: 0.5585):\n",
      "  This report describes the condition of Texas pavements in Fiscal Year 2007 and during the four-\n",
      "year FY 2004-2007 period, based on analysis of Pavement Management Information System \n",
      "(PMIS) distress ratings and ride quality measurements.  The report includes the major highway \n",
      "systems (IH, US, SH, and FM) and pavement types (ACP, CRCP, and JCP), along with \n",
      "maintenance level of service information, pavement-related performance measures, and \n",
      "estimates of preventive maintenance and rehabilitation needs. \n",
      "“Distress” refers to various types of surface deterioration (such as ruts, cracks, potholes/failures, \n",
      "and patches).  “Ride quality” refers to the smoothness of the pavement surface.  “Condition” is a \n",
      "mathematical combination of the “distress” and “ride quality” data that describes the average \n",
      "person’s perception of pavement quality. \n",
      "The overall condition of Texas pavements got slightly worse in FY 2007 mainly because of\n",
      "HNSW Result 5 (Distance: 0.5538):\n",
      "  For Farm-to-Market roads (FM), FY 2007 condition and distress got worse, but ride quality \n",
      "improved.  Deep Distress Scores on FM roads got worse, though.  Despite the worsening Deep \n",
      "Distress Scores in FY 2007, FM roads still had the best overall “deep” distress, as they have had \n",
      "since FY 2004.  FM roads had the worst overall ride quality of the major highway systems in FY \n",
      "2007 (as they have had since FY 2001) and the worst overall condition. \n",
      "Summary \n",
      "Pavement condition and distress trends were mixed, but ride quality improved for each of the \n",
      "four major highway systems (IH, US, SH, and FM) in FY 2007. \n",
      "IH and SH routes improved in all categories – condition, distress, ride, and “deep” distress – in \n",
      "FY 2007.  US highways improved in distress, “deep” distress, and ride, but the improvements \n",
      "were all very small, and were not enough to keep the overall condition from getting worse.  FM \n",
      "roads improved in ride quality, but got worse in condition, distress, and “deep” distress.\n",
      "\n",
      "--- Search Results (IVF_FLAT Index) ---\n",
      "\n",
      "Embedding query: 'How are the condition of roads in general ?'...\n",
      "Searching collection 'document_chunks_ivf' with top_k=5...\n",
      "Retrieved 5 relevant chunks from 'document_chunks_ivf'.\n",
      "IVF_FLAT Result 1 (Distance: 0.5817):\n",
      "  person’s perception of pavement quality. \n",
      "The overall condition of Texas pavements got slightly worse in FY 2007 mainly because of \n",
      "increased distress on asphalt pavements.  Overall pavement distress got worse, but overall ride \n",
      "quality improved.  A prolonged drought that began in mid-FY 2005 and lasted through all of FY \n",
      "2006, rising material costs, increased competition for limited construction materials, and \n",
      "increased oilfield development traffic contributed to the decline in statewide pavement condition. \n",
      "Although overall pavement condition declined, the statewide pavement condition goal \n",
      "percentage of lane miles in “Good” or better condition increased from 86.69 percent in FY 2006 \n",
      "to 86.76 percent in FY 2007.   \n",
      "Pavement condition and distress trends were mixed, but ride quality improved for each of the \n",
      "four major highway systems (IH, US, SH, and FM) in FY 2007.  IH and SH routes improved in\n",
      "IVF_FLAT Result 2 (Distance: 0.5593):\n",
      "  increased oilfield development traffic contributed to the decline in statewide pavement condition. \n",
      "Pavement condition and distress trends were mixed, but ride quality improved for each of the \n",
      "four major highway systems (IH, US, SH, and FM) in FY 2007.  IH and SH routes improved in \n",
      "all categories – condition, distress, ride, and “deep” distress.  US highways improved in distress, \n",
      "“deep” distress, and ride, but the improvements were all very small, and were not enough to keep \n",
      "the overall condition from getting worse.  FM roads improved in ride quality, but got worse in \n",
      "condition, distress, and “deep” distress. \n",
      "ACP condition and distress got worse, but ride quality improved in FY 2007.  “Deep” distress on \n",
      "improved because of a large reduction in Alligator Cracking.  ACP had the best overall condition \n",
      "and ride quality of the three major pavement types in FY 2007.  Shallow Rutting, Deep Rutting,\n",
      "IVF_FLAT Result 3 (Distance: 0.5587):\n",
      "  ♦ Data analyzed in this report was obtained from all PMIS sections, mainlane roadbeds, \n",
      "Condition Scores greater than 0, excluding sections under construction.  This analysis \n",
      "was consistent for the entire report except for the following portions of Chapter 7: \n",
      "♦ UTP Category 1 pages were based on all PMIS sections, mainlanes and frontage roads, \n",
      "Distress Score or Ride Score greater than 0 (where applicable), excluding sections under \n",
      "construction. \n",
      "♦ FHWA NHS ride quality tables were based on NHS sections, mainlanes only, with IRI \n",
      "left and right wheelpath greater than 0. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Cover Photo: \n",
      "IH 35 in Temple, Waco District \n",
      "Photo by Stan Williams, TxDOT.\n",
      "Condition of Texas Pavements, FY 2004-2007  i \n",
      " \n",
      "Executive Summary \n",
      "This report describes the condition of Texas pavements in Fiscal Year 2007 and during the four-\n",
      "year FY 2004-2007 period, based on analysis of Pavement Management Information System\n",
      "IVF_FLAT Result 4 (Distance: 0.5585):\n",
      "  This report describes the condition of Texas pavements in Fiscal Year 2007 and during the four-\n",
      "year FY 2004-2007 period, based on analysis of Pavement Management Information System \n",
      "(PMIS) distress ratings and ride quality measurements.  The report includes the major highway \n",
      "systems (IH, US, SH, and FM) and pavement types (ACP, CRCP, and JCP), along with \n",
      "maintenance level of service information, pavement-related performance measures, and \n",
      "estimates of preventive maintenance and rehabilitation needs. \n",
      "“Distress” refers to various types of surface deterioration (such as ruts, cracks, potholes/failures, \n",
      "and patches).  “Ride quality” refers to the smoothness of the pavement surface.  “Condition” is a \n",
      "mathematical combination of the “distress” and “ride quality” data that describes the average \n",
      "person’s perception of pavement quality. \n",
      "The overall condition of Texas pavements got slightly worse in FY 2007 mainly because of\n",
      "IVF_FLAT Result 5 (Distance: 0.5538):\n",
      "  For Farm-to-Market roads (FM), FY 2007 condition and distress got worse, but ride quality \n",
      "improved.  Deep Distress Scores on FM roads got worse, though.  Despite the worsening Deep \n",
      "Distress Scores in FY 2007, FM roads still had the best overall “deep” distress, as they have had \n",
      "since FY 2004.  FM roads had the worst overall ride quality of the major highway systems in FY \n",
      "2007 (as they have had since FY 2001) and the worst overall condition. \n",
      "Summary \n",
      "Pavement condition and distress trends were mixed, but ride quality improved for each of the \n",
      "four major highway systems (IH, US, SH, and FM) in FY 2007. \n",
      "IH and SH routes improved in all categories – condition, distress, ride, and “deep” distress – in \n",
      "FY 2007.  US highways improved in distress, “deep” distress, and ride, but the improvements \n",
      "were all very small, and were not enough to keep the overall condition from getting worse.  FM \n",
      "roads improved in ride quality, but got worse in condition, distress, and “deep” distress.\n",
      "\n",
      "--- Search Results (FLAT Index) ---\n",
      "\n",
      "Embedding query: 'How are the condition of roads in general ?'...\n",
      "Searching collection 'document_chunks_flat' with top_k=5...\n",
      "Retrieved 5 relevant chunks from 'document_chunks_flat'.\n",
      "FLAT Result 1 (Distance: 0.5817):\n",
      "  person’s perception of pavement quality. \n",
      "The overall condition of Texas pavements got slightly worse in FY 2007 mainly because of \n",
      "increased distress on asphalt pavements.  Overall pavement distress got worse, but overall ride \n",
      "quality improved.  A prolonged drought that began in mid-FY 2005 and lasted through all of FY \n",
      "2006, rising material costs, increased competition for limited construction materials, and \n",
      "increased oilfield development traffic contributed to the decline in statewide pavement condition. \n",
      "Although overall pavement condition declined, the statewide pavement condition goal \n",
      "percentage of lane miles in “Good” or better condition increased from 86.69 percent in FY 2006 \n",
      "to 86.76 percent in FY 2007.   \n",
      "Pavement condition and distress trends were mixed, but ride quality improved for each of the \n",
      "four major highway systems (IH, US, SH, and FM) in FY 2007.  IH and SH routes improved in\n",
      "FLAT Result 2 (Distance: 0.5593):\n",
      "  increased oilfield development traffic contributed to the decline in statewide pavement condition. \n",
      "Pavement condition and distress trends were mixed, but ride quality improved for each of the \n",
      "four major highway systems (IH, US, SH, and FM) in FY 2007.  IH and SH routes improved in \n",
      "all categories – condition, distress, ride, and “deep” distress.  US highways improved in distress, \n",
      "“deep” distress, and ride, but the improvements were all very small, and were not enough to keep \n",
      "the overall condition from getting worse.  FM roads improved in ride quality, but got worse in \n",
      "condition, distress, and “deep” distress. \n",
      "ACP condition and distress got worse, but ride quality improved in FY 2007.  “Deep” distress on \n",
      "improved because of a large reduction in Alligator Cracking.  ACP had the best overall condition \n",
      "and ride quality of the three major pavement types in FY 2007.  Shallow Rutting, Deep Rutting,\n",
      "FLAT Result 3 (Distance: 0.5587):\n",
      "  ♦ Data analyzed in this report was obtained from all PMIS sections, mainlane roadbeds, \n",
      "Condition Scores greater than 0, excluding sections under construction.  This analysis \n",
      "was consistent for the entire report except for the following portions of Chapter 7: \n",
      "♦ UTP Category 1 pages were based on all PMIS sections, mainlanes and frontage roads, \n",
      "Distress Score or Ride Score greater than 0 (where applicable), excluding sections under \n",
      "construction. \n",
      "♦ FHWA NHS ride quality tables were based on NHS sections, mainlanes only, with IRI \n",
      "left and right wheelpath greater than 0. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Cover Photo: \n",
      "IH 35 in Temple, Waco District \n",
      "Photo by Stan Williams, TxDOT.\n",
      "Condition of Texas Pavements, FY 2004-2007  i \n",
      " \n",
      "Executive Summary \n",
      "This report describes the condition of Texas pavements in Fiscal Year 2007 and during the four-\n",
      "year FY 2004-2007 period, based on analysis of Pavement Management Information System\n",
      "FLAT Result 4 (Distance: 0.5585):\n",
      "  This report describes the condition of Texas pavements in Fiscal Year 2007 and during the four-\n",
      "year FY 2004-2007 period, based on analysis of Pavement Management Information System \n",
      "(PMIS) distress ratings and ride quality measurements.  The report includes the major highway \n",
      "systems (IH, US, SH, and FM) and pavement types (ACP, CRCP, and JCP), along with \n",
      "maintenance level of service information, pavement-related performance measures, and \n",
      "estimates of preventive maintenance and rehabilitation needs. \n",
      "“Distress” refers to various types of surface deterioration (such as ruts, cracks, potholes/failures, \n",
      "and patches).  “Ride quality” refers to the smoothness of the pavement surface.  “Condition” is a \n",
      "mathematical combination of the “distress” and “ride quality” data that describes the average \n",
      "person’s perception of pavement quality. \n",
      "The overall condition of Texas pavements got slightly worse in FY 2007 mainly because of\n",
      "FLAT Result 5 (Distance: 0.5538):\n",
      "  For Farm-to-Market roads (FM), FY 2007 condition and distress got worse, but ride quality \n",
      "improved.  Deep Distress Scores on FM roads got worse, though.  Despite the worsening Deep \n",
      "Distress Scores in FY 2007, FM roads still had the best overall “deep” distress, as they have had \n",
      "since FY 2004.  FM roads had the worst overall ride quality of the major highway systems in FY \n",
      "2007 (as they have had since FY 2001) and the worst overall condition. \n",
      "Summary \n",
      "Pavement condition and distress trends were mixed, but ride quality improved for each of the \n",
      "four major highway systems (IH, US, SH, and FM) in FY 2007. \n",
      "IH and SH routes improved in all categories – condition, distress, ride, and “deep” distress – in \n",
      "FY 2007.  US highways improved in distress, “deep” distress, and ride, but the improvements \n",
      "were all very small, and were not enough to keep the overall condition from getting worse.  FM \n",
      "roads improved in ride quality, but got worse in condition, distress, and “deep” distress.\n",
      "\n",
      "Step 4 (Milvus Retrieval Pipeline) completed.\n",
      "You can now see how different indexes perform for your queries.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pymilvus import connections, utility, Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Any\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# --- Configuration for Milvus Connection ---\n",
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "\n",
    "COLLECTION_NAME = \"document_chunks\"\n",
    "\n",
    "# --- Embedding Model Configuration ---\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "VECTOR_DIMENSION = 384 \n",
    "\n",
    "embedding_model = None \n",
    "\n",
    "def connect_to_milvus():\n",
    "    try:\n",
    "        print(f\"Attempting to connect to Milvus at {MILVUS_HOST}:{MILVUS_PORT}...\")\n",
    "        connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "        # Verify connection by listing collections (or any other utility command)\n",
    "        utility.list_collections()\n",
    "        print(\"Milvus connection successful!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Milvus connection failed: {e}\")\n",
    "        print(\"Please ensure your Milvus Docker container is running (run 'docker ps').\")\n",
    "        return False\n",
    "\n",
    "def get_embedding_model():\n",
    "    \"\"\"Loads and returns the SentenceTransformer embedding model.\"\"\"\n",
    "    global embedding_model\n",
    "    if embedding_model is None:\n",
    "        # Define the local directory where the model will be downloaded/loaded from\n",
    "        # This will be a subfolder within your working directory\n",
    "        local_model_dir = os.path.join(os.getcwd(), \"downloaded_embedding_model\", EMBEDDING_MODEL_NAME.replace(\"/\", \"--\"))\n",
    "        os.makedirs(local_model_dir, exist_ok=True) # Ensure the directory exists\n",
    "        print(f\"Attempting to load model from or download to: {local_model_dir}\")\n",
    "\n",
    "        try:\n",
    "            config_path = os.path.join(local_model_dir, \"config.json\")\n",
    "            \n",
    "            if not os.path.exists(config_path) or not os.path.exists(os.path.join(local_model_dir, \"pytorch_model.bin\")):\n",
    "                print(f\"Model files not found or incomplete in '{local_model_dir}'. Initiating robust download...\")\n",
    "                snapshot_download(\n",
    "                    repo_id=f\"sentence-transformers/{EMBEDDING_MODEL_NAME}\",\n",
    "                    local_dir=local_model_dir,\n",
    "                    local_dir_use_symlinks=False, \n",
    "                    resume_download=True \n",
    "                )\n",
    "                print(f\"Model successfully downloaded to: {local_model_dir}\")\n",
    "            else:\n",
    "                print(f\"Model files found in '{local_model_dir}'. Loading from local directory.\")\n",
    "\n",
    "            # Now, load the model directly from the local directory\n",
    "            embedding_model = SentenceTransformer(local_model_dir, model_kwargs={'device': 'cpu'})\n",
    "            print(\"Embedding model loaded successfully from local path.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading embedding model {EMBEDDING_MODEL_NAME} from '{local_model_dir}': {e}\")\n",
    "            print(\"Please ensure you have an active internet connection for the initial download.\")\n",
    "            print(\"If issues persist, check permissions for the 'downloaded_embedding_model' directory.\")\n",
    "            embedding_model = None\n",
    "    return embedding_model\n",
    "\n",
    "def get_milvus_collection(collection_suffix: str) -> Collection:\n",
    "    full_collection_name = f\"{COLLECTION_NAME}_{collection_suffix}\"\n",
    "    if not utility.has_collection(full_collection_name):\n",
    "        print(f\"Error: Collection '{full_collection_name}' does not exist.\")\n",
    "        print(\"Please run milvus_full_setup_ingestion.py first to create and populate collections.\")\n",
    "        return None\n",
    "    collection = Collection(full_collection_name)\n",
    "    \n",
    "    # Load the collection into memory for searching if not already loaded\n",
    "    try:\n",
    "        print(f\"Loading collection '{collection.name}' into memory for search...\")\n",
    "        collection.load()\n",
    "        print(f\"Collection '{collection.name}' loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading collection '{collection.name}': {e}\")\n",
    "        return None\n",
    "            \n",
    "    return collection\n",
    "\n",
    "def retrieve_relevant_chunks(query_text: str, collection: Collection, top_k: int = 3) -> List[Dict[str, Any]]:\n",
    "    if not collection:\n",
    "        print(f\"Collection '{collection.name if collection else 'unknown'}' not available or not loaded for search.\")\n",
    "        return []\n",
    "\n",
    "    model = get_embedding_model()\n",
    "    if not model:\n",
    "        print(\"Embedding model not loaded. Cannot embed query.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"\\nEmbedding query: '{query_text}'...\")\n",
    "    query_embedding = model.encode(query_text).tolist() # Encode and convert to list\n",
    "\n",
    "    # Milvus search parameters\n",
    "    # The 'params' depend on the index type.\n",
    "    # For HNSW, the important param is 'ef' (exploration factor). Higher ef means better recall, slower search.\n",
    "    # For IVF_FLAT, the important param is 'nprobe' (number of clusters to search). Higher nprobe means better recall, slower search.\n",
    "    # For FLAT, there are no specific search params other than metric_type.\n",
    "\n",
    "    search_params = {\n",
    "        \"data\": [query_embedding],\n",
    "        \"anns_field\": \"embedding\",\n",
    "        \"limit\": top_k,\n",
    "        \"output_fields\": [\"page_content\"], # Fields to retrieve along with vector similarity results\n",
    "        \"expr\": \"pk > 0\"\n",
    "    }\n",
    "\n",
    "    # Adjust search parameters based on index type\n",
    "    if \"hnsw\" in collection.name:\n",
    "        search_params[\"param\"] = {\"metric_type\": \"COSINE\", \"params\": {\"ef\": 64}} # ef usually between top_k and efConstruction\n",
    "    elif \"ivf\" in collection.name:\n",
    "        search_params[\"param\"] = {\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}} # nprobe should be <= nlist (1024)\n",
    "    elif \"flat\" in collection.name:\n",
    "        search_params[\"param\"] = {\"metric_type\": \"COSINE\", \"params\": {}} # FLAT has no specific search params\n",
    "\n",
    "    print(f\"Searching collection '{collection.name}' with top_k={top_k}...\")\n",
    "    try:\n",
    "        results = collection.search(**search_params)\n",
    "\n",
    "        retrieved_chunks = []\n",
    "        for hit in results[0]:\n",
    "            retrieved_chunks.append({\n",
    "                \"page_content\": hit.entity.get(\"page_content\"),\n",
    "                \"distance\": hit.distance\n",
    "            })\n",
    "        print(f\"Retrieved {len(retrieved_chunks)} relevant chunks from '{collection.name}'.\")\n",
    "        return retrieved_chunks\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search in '{collection.name}': {e}\")\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import pymilvus\n",
    "        import json\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "    except ImportError as e:\n",
    "        print(f\"Missing required library: {e}. Please install using:\")\n",
    "        print(\"pip install pymilvus sentence-transformers\")\n",
    "        exit()\n",
    "\n",
    "    # Connect to Milvus\n",
    "    if not connect_to_milvus():\n",
    "        exit()\n",
    "\n",
    "    # Get Milvus Collections\n",
    "    print(\"\\n--- Retrieving Milvus Collections ---\")\n",
    "    hnsw_collection = get_milvus_collection(\"hnsw\")\n",
    "    ivf_collection = get_milvus_collection(\"ivf\")\n",
    "    flat_collection = get_milvus_collection(\"flat\")\n",
    "\n",
    "    if not all([hnsw_collection, ivf_collection, flat_collection]):\n",
    "        print(\"Not all required Milvus collections are available or loaded. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Get Embedding Model (will download if not present)\n",
    "    model = get_embedding_model()\n",
    "    if not model:\n",
    "        print(\"Failed to load embedding model. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Interactive Search Loop\n",
    "    print(\"\\n--- Starting Interactive Retrieval ---\")\n",
    "    print(\"Enter 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        query = input(\"\\nEnter your query: \")\n",
    "        if query.lower() == 'exit':\n",
    "            break\n",
    "\n",
    "        print(\"\\n--- Search Results (HNSW Index) ---\")\n",
    "        hnsw_results = retrieve_relevant_chunks(query, hnsw_collection, top_k=5)\n",
    "        if hnsw_results:\n",
    "            for i, chunk in enumerate(hnsw_results):\n",
    "                print(f\"HNSW Result {i+1} (Distance: {chunk['distance']:.4f}):\")\n",
    "                print(f\"  {chunk['page_content'].strip()}\")\n",
    "        else:\n",
    "            print(\"No results found from HNSW index.\")\n",
    "\n",
    "        print(\"\\n--- Search Results (IVF_FLAT Index) ---\")\n",
    "        ivf_results = retrieve_relevant_chunks(query, ivf_collection, top_k=5)\n",
    "        if ivf_results:\n",
    "            for i, chunk in enumerate(ivf_results):\n",
    "                print(f\"IVF_FLAT Result {i+1} (Distance: {chunk['distance']:.4f}):\")\n",
    "                print(f\"  {chunk['page_content'].strip()}\")\n",
    "        else:\n",
    "            print(\"No results found from IVF_FLAT index.\")\n",
    "        \n",
    "        print(\"\\n--- Search Results (FLAT Index) ---\")\n",
    "        flat_results = retrieve_relevant_chunks(query, flat_collection, top_k=5)\n",
    "        if flat_results:\n",
    "            for i, chunk in enumerate(flat_results):\n",
    "                print(f\"FLAT Result {i+1} (Distance: {chunk['distance']:.4f}):\")\n",
    "                print(f\"  {chunk['page_content'].strip()}\")\n",
    "        else:\n",
    "            print(\"No results found from FLAT index.\")\n",
    "\n",
    "\n",
    "    print(\"\\nStep 4 (Milvus Retrieval Pipeline) completed.\")\n",
    "    print(\"You can now see how different indexes perform for your queries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33bf95",
   "metadata": {},
   "source": [
    "# STEP 5 -- Prompt Template and Generate output through LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc16fd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to connect to Milvus at localhost:19530...\n",
      "Milvus connection successful!\n",
      "\n",
      "--- Retrieving Milvus Collections ---\n",
      "Loading collection 'document_chunks_hnsw' into memory for search...\n",
      "Collection 'document_chunks_hnsw' loaded.\n",
      "Attempting to load model from or download to: /Users/nitin/AgenticAI_Assignments/RAG_Assignment_1/downloaded_embedding_model/all-MiniLM-L6-v2\n",
      "Model files found in '/Users/nitin/AgenticAI_Assignments/RAG_Assignment_1/downloaded_embedding_model/all-MiniLM-L6-v2'. Loading from local directory.\n",
      "Embedding model loaded successfully from local path.\n",
      "\n",
      "--- Starting Interactive RAG Pipeline ---\n",
      "Enter 'exit' to quit.\n",
      "\n",
      "Retrieving relevant chunks for query: 'What is you assesment about Roads ?'\n",
      "\n",
      "Embedding query: 'What is you assesment about Roads ?'...\n",
      "Searching collection 'document_chunks_hnsw' with top_k=5...\n",
      "Retrieved 5 relevant chunks from 'document_chunks_hnsw'.\n",
      "\n",
      "Generating LLM response...\n",
      "\n",
      "Sending request to Gemini LLM...\n",
      "\n",
      "--- RAG Response ---\n",
      "Query: What is you assesment about Roads ?\n",
      "\n",
      "Retrieved Context:\n",
      "  Chunk 1: decreased in FY 2007.  This trend does not match the observed improvement in overall ACP \n",
      "Ride Quality described in Chapter 3, because of an increase in the number of lane miles rated in \n",
      "FY 2007.  There were actually 679.2 more lane miles in “Desirable” or “Acceptable” level of \n",
      "service in FY 2007.  These additional lane miles made the overall Ride Quality in Chapter 3 go \n",
      "up, but they were not enough to offset the 828.1 additional lane miles rated that drove down the \n",
      "level of service percentage. \n",
      "The overall level of service for “Low-traffic” and “Medium-traffic” mileage got worse, while \n",
      "“High-traffic” level of service did not change in FY 2007.  “High-traffic” roads continued to \n",
      "carry the majority of vehicle miles traveled — 56.25 percent in FY 2007 — despite being only \n",
      "13.89 percent of the lane miles.  This means that more than half of the public’s perception of the \n",
      "overall quality of Texas pavements was based on the condition of these “high-traffic” roads.\n",
      "  Chunk 2: ♦ “Fair” mileage increased (from 30.04% in 2006 to 30.11% in 2007) \n",
      "♦ “Poor” mileage decreased (from 22.90% in 2006 to 22.01% in 2007) \n",
      "♦ “Very Poor” mileage decreased (from 13.46% in 2006 to 13.13% in 2007). \n",
      " \n",
      " \n",
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "“Very Good” “Good” “Fair” “Poor” “Very Poor”\n",
      "PMIS IRI Score Class\n",
      "Lane Miles, Percent\n",
      "2004 2005 2006 2007\n",
      "Condition of Texas Pavements, FY 2004-2007 Chapter 3 85 \n",
      "What are those roads that parallel the Interstate mainlanes? \n",
      " \n",
      "TxDOT officially calls them “frontage roads,” but several cities \n",
      "have their own names for them.  In Houston, they are called \n",
      "“feeder” roads; in Dallas-Fort Worth, “service” roads; in San \n",
      "Antonio, “access” roads; and in El Paso, “gateway” roads.   \n",
      " \n",
      "Source:  Texas Transportation Institute.\n",
      "86 Chapter 3 Condition of Texas Pavements, FY 2004-2007 \n",
      "Shallow Rutting \n",
      "Figure 3.6 shows the percentage of PMIS sections with Shallow Rutting for fiscal years 2004\n",
      "  Chunk 3: FY 2007.\n",
      "178 Chapter 6 Condition of Texas Pavements, FY 2004-2007 \n",
      "There is no requirement that one in five miles of the Interstate \n",
      "System be straight so that airplanes can land in emergencies.  \n",
      "Airplanes do occasionally land on Interstate highways when no \n",
      "alternative is available in an emergency, but not because the \n",
      "Interstates are designed for that purpose.  Source:  FHWA.\n",
      "Condition of Texas Pavements, FY 2004-2007 Chapter 7 179 \n",
      "Chapter 7  Performance Measures \n",
      "This report has shown that there are many ways to describe the condition of Texas pavements.  \n",
      "No matter which method is used, the intent is the same:  to produce pavements that provide safe \n",
      "and efficient transport of people and goods.  To meet this intent, TxDOT defines performance \n",
      "measures and adjusts funding, as necessary, to improve the overall condition of Texas \n",
      "pavements.  These performance measures are then used for TxDOT pavement management, for\n",
      "  Chunk 4: “High-traffic” roads stayed the same overall in FY 2007.  A seven percent drop in “Desirable” \n",
      "mileage was matched by a seven percent rise in “Acceptable” mileage, and a one percent drop in \n",
      "“Acceptable” mileage was matched by a one percent rise in “Intolerable” mileage. \n",
      "“High-traffic” roads accounted for only 13.89 percent of the lane miles but 56.25 percent of the \n",
      "vehicles miles traveled in FY 2007.  Both of these percentages increased in FY 2007. \n",
      "From a public service standpoint, it is preferable to have high-traffic roads in the best condition, \n",
      "but from a pavement standpoint this is difficult to do because of the higher traffic volumes and \n",
      "loads.  Safety, congestion, user delay, and scheduling add to the problem of not being able to get \n",
      "out on the road to do preventive maintenance to keep the road in good condition.  The problem is \n",
      "that when preventive maintenance is not done when needed, pavement condition drops, the\n",
      "  Chunk 5: person’s perception of pavement quality. \n",
      "The overall condition of Texas pavements got slightly worse in FY 2007 mainly because of \n",
      "increased distress on asphalt pavements.  Overall pavement distress got worse, but overall ride \n",
      "quality improved.  A prolonged drought that began in mid-FY 2005 and lasted through all of FY \n",
      "2006, rising material costs, increased competition for limited construction materials, and \n",
      "increased oilfield development traffic contributed to the decline in statewide pavement condition. \n",
      "Although overall pavement condition declined, the statewide pavement condition goal \n",
      "percentage of lane miles in “Good” or better condition increased from 86.69 percent in FY 2006 \n",
      "to 86.76 percent in FY 2007.   \n",
      "Pavement condition and distress trends were mixed, but ride quality improved for each of the \n",
      "four major highway systems (IH, US, SH, and FM) in FY 2007.  IH and SH routes improved in\n",
      "\n",
      "Answer: The overall condition of Texas pavements got slightly worse in FY 2007 mainly because of increased distress on asphalt pavements, but overall ride quality improved. The level of service for “Low-traffic” and “Medium-traffic” mileage got worse, while the “High-traffic” level of service did not change in FY 2007.\n",
      "\n",
      "--------------------\n",
      "\n",
      "Step 5 (RAG LLM Generation) completed. Exiting RAG pipeline.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pymilvus import connections, utility, Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Any\n",
    "from huggingface_hub import snapshot_download\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# --- Configuration for Milvus Connection ---\n",
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "\n",
    "COLLECTION_NAME = \"document_chunks\"\n",
    "\n",
    "# --- Embedding Model Configuration ---\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "VECTOR_DIMENSION = 384\n",
    "embedding_model = None\n",
    "\n",
    "# --- Gemini API Configuration ---\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
    "\n",
    "def connect_to_milvus():\n",
    "    try:\n",
    "        print(f\"Attempting to connect to Milvus at {MILVUS_HOST}:{MILVUS_PORT}...\")\n",
    "        connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "        utility.list_collections() # Verify connection\n",
    "        print(\"Milvus connection successful!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Milvus connection failed: {e}\")\n",
    "        print(\"Please ensure your Milvus Docker container is running (run 'docker ps').\")\n",
    "        return False\n",
    "\n",
    "def get_embedding_model():\n",
    "    global embedding_model\n",
    "    if embedding_model is None:\n",
    "        local_model_dir = os.path.join(os.getcwd(), \"downloaded_embedding_model\", EMBEDDING_MODEL_NAME.replace(\"/\", \"--\"))\n",
    "        os.makedirs(local_model_dir, exist_ok=True) # Ensure the directory exists\n",
    "        print(f\"Attempting to load model from or download to: {local_model_dir}\")\n",
    "\n",
    "        try:\n",
    "            config_path = os.path.join(local_model_dir, \"config.json\")\n",
    "            \n",
    "            if not os.path.exists(config_path) or not os.path.exists(os.path.join(local_model_dir, \"pytorch_model.bin\")):\n",
    "                print(f\"Model files not found or incomplete in '{local_model_dir}'. Initiating robust download...\")\n",
    "                snapshot_download(\n",
    "                    repo_id=f\"sentence-transformers/{EMBEDDING_MODEL_NAME}\",\n",
    "                    local_dir=local_model_dir,\n",
    "                    local_dir_use_symlinks=False,\n",
    "                    resume_download=True\n",
    "                )\n",
    "                print(f\"Model successfully downloaded to: {local_model_dir}\")\n",
    "            else:\n",
    "                print(f\"Model files found in '{local_model_dir}'. Loading from local directory.\")\n",
    "\n",
    "            embedding_model = SentenceTransformer(local_model_dir, model_kwargs={'device': 'cpu'})\n",
    "            print(\"Embedding model loaded successfully from local path.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading embedding model {EMBEDDING_MODEL_NAME} from '{local_model_dir}': {e}\")\n",
    "            print(\"Please ensure you have an active internet connection for the initial download.\")\n",
    "            print(\"If issues persist, check permissions for the 'downloaded_embedding_model' directory.\")\n",
    "            embedding_model = None\n",
    "    return embedding_model\n",
    "\n",
    "def get_milvus_collection(collection_suffix: str) -> Collection:\n",
    "    full_collection_name = f\"{COLLECTION_NAME}_{collection_suffix}\"\n",
    "    if not utility.has_collection(full_collection_name):\n",
    "        print(f\"Error: Collection '{full_collection_name}' does not exist.\")\n",
    "        print(\"Please run milvus_full_setup_ingestion.py first to create and populate collections.\")\n",
    "        return None\n",
    "    collection = Collection(full_collection_name)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading collection '{collection.name}' into memory for search...\")\n",
    "        collection.load()\n",
    "        print(f\"Collection '{collection.name}' loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading collection '{collection.name}': {e}\")\n",
    "        return None\n",
    "            \n",
    "    return collection\n",
    "\n",
    "def retrieve_relevant_chunks(query_text: str, collection: Collection, top_k: int = 3) -> List[Dict[str, Any]]:\n",
    "    if not collection:\n",
    "        print(f\"Collection '{collection.name if collection else 'unknown'}' not available for search.\")\n",
    "        return []\n",
    "\n",
    "    model = get_embedding_model()\n",
    "    if not model:\n",
    "        print(\"Embedding model not loaded. Cannot embed query.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"\\nEmbedding query: '{query_text}'...\")\n",
    "    query_embedding = model.encode(query_text).tolist()\n",
    "\n",
    "    search_params = {\n",
    "        \"data\": [query_embedding],\n",
    "        \"anns_field\": \"embedding\",\n",
    "        \"limit\": top_k,\n",
    "        \"output_fields\": [\"page_content\"],\n",
    "        \"expr\": \"pk > 0\"\n",
    "    }\n",
    "\n",
    "    if \"hnsw\" in collection.name:\n",
    "        search_params[\"param\"] = {\"metric_type\": \"COSINE\", \"params\": {\"ef\": 64}}\n",
    "    elif \"ivf\" in collection.name:\n",
    "        search_params[\"param\"] = {\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}}\n",
    "    elif \"flat\" in collection.name:\n",
    "        search_params[\"param\"] = {\"metric_type\": \"COSINE\", \"params\": {}}\n",
    "\n",
    "    print(f\"Searching collection '{collection.name}' with top_k={top_k}...\")\n",
    "    try:\n",
    "        results = collection.search(**search_params)\n",
    "\n",
    "        retrieved_chunks = []\n",
    "        for hit in results[0]:\n",
    "            retrieved_chunks.append({\n",
    "                \"page_content\": hit.entity.get(\"page_content\"),\n",
    "                \"distance\": hit.distance\n",
    "            })\n",
    "        print(f\"Retrieved {len(retrieved_chunks)} relevant chunks from '{collection.name}'.\")\n",
    "        return retrieved_chunks\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search in '{collection.name}': {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_llm_response(query: str, context_chunks: List[str]) -> str:\n",
    "    if not context_chunks:\n",
    "        print(\"No context chunks provided for LLM. Generating response without context.\")\n",
    "        context_str = \"No relevant context available.\"\n",
    "    else:\n",
    "        context_str = \"\\n\".join([f\"Chunk {i+1}: {chunk}\" for i, chunk in enumerate(context_chunks)])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant specialized in answering questions based on provided information.\n",
    "    Answer the user's query truthfully and concisely, using ONLY the context provided below.\n",
    "    If the answer cannot be found in the context, state that you don't have enough information.\n",
    "\n",
    "    User Query: {query}\n",
    "\n",
    "    Context:\n",
    "    {context_str}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    chat_history = []\n",
    "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt}]})\n",
    "\n",
    "    payload = {\"contents\": chat_history}\n",
    "    \n",
    "    # Check if GEMINI_API_KEY is empty, if so, Canvas will inject it.\n",
    "    api_key_param = f\"?key={GEMINI_API_KEY}\" if GEMINI_API_KEY else \"\"\n",
    "    api_url_with_key = f\"{GEMINI_API_URL}{api_key_param}\"\n",
    "\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    print(\"\\nSending request to Gemini LLM...\")\n",
    "    try:\n",
    "        response = requests.post(api_url_with_key, headers=headers, json=payload)\n",
    "        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
    "        result = response.json()\n",
    "\n",
    "        if result.get(\"candidates\") and result[\"candidates\"][0].get(\"content\") and result[\"candidates\"][0][\"content\"].get(\"parts\"):\n",
    "            llm_response = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "            return llm_response\n",
    "        else:\n",
    "            print(f\"Unexpected API response format: {result}\")\n",
    "            return \"Could not generate a response from the LLM due to an unexpected API format.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during Gemini API call: {e}\")\n",
    "        return \"An error occurred while communicating with the LLM API.\"\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during LLM response generation: {e}\")\n",
    "        return \"An unexpected error occurred during LLM response generation.\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import pymilvus\n",
    "        import json\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        from huggingface_hub import snapshot_download\n",
    "        import requests # Make sure requests is imported here\n",
    "    except ImportError as e:\n",
    "        print(f\"Missing required library: {e}. Please install using:\")\n",
    "        print(\"pip install pymilvus sentence-transformers huggingface-hub requests\")\n",
    "        exit()\n",
    "\n",
    "    # Connect to Milvus\n",
    "    if not connect_to_milvus():\n",
    "        exit()\n",
    "\n",
    "    # Get Milvus Collections (using HNSW for RAG, you can choose another)\n",
    "    print(\"\\n--- Retrieving Milvus Collections ---\")\n",
    "    hnsw_collection = get_milvus_collection(\"hnsw\")\n",
    "    \n",
    "    if not hnsw_collection:\n",
    "        print(\"Required Milvus HNSW collection not available or loaded. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Get Embedding Model\n",
    "    model = get_embedding_model()\n",
    "    if not model:\n",
    "        print(\"Failed to load embedding model. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Interactive RAG Loop\n",
    "    print(\"\\n--- Starting Interactive RAG Pipeline ---\")\n",
    "    print(\"Enter 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nEnter your query: \")\n",
    "        if user_query.lower() == 'exit':\n",
    "            break\n",
    "\n",
    "        # Retrieve relevant chunks using the HNSW index\n",
    "        print(f\"\\nRetrieving relevant chunks for query: '{user_query}'\")\n",
    "        retrieved_chunks = retrieve_relevant_chunks(user_query, hnsw_collection, top_k=5) # Get top 5 chunks\n",
    "\n",
    "        # Extract only the page_content for the LLM context\n",
    "        context_for_llm = [chunk['page_content'] for chunk in retrieved_chunks]\n",
    "        \n",
    "        # Generate LLM response\n",
    "        print(\"\\nGenerating LLM response...\")\n",
    "        llm_answer = generate_llm_response(user_query, context_for_llm)\n",
    "\n",
    "        print(\"\\n--- RAG Response ---\")\n",
    "        print(f\"Query: {user_query}\")\n",
    "        print(\"\\nRetrieved Context:\")\n",
    "        if context_for_llm:\n",
    "            for i, chunk in enumerate(context_for_llm):\n",
    "                print(f\"  Chunk {i+1}: {chunk.strip()}\")\n",
    "        else:\n",
    "            print(\"  No relevant context retrieved.\")\n",
    "        print(f\"\\nAnswer: {llm_answer}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "    print(\"\\nStep 5 (RAG LLM Generation) completed. Exiting RAG pipeline.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d105ea",
   "metadata": {},
   "source": [
    "# STEP 6 -- RETRIEVAL EVALUATION AND RE-RANKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730a5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to connect to Milvus at localhost:19530...\n",
      "Milvus connection successful!\n",
      "\n",
      "--- Retrieving Milvus Collections ---\n",
      "Loading collection 'document_chunks_hnsw' into memory for search...\n",
      "Collection 'document_chunks_hnsw' loaded.\n",
      "Loading collection 'document_chunks_ivf' into memory for search...\n",
      "Collection 'document_chunks_ivf' loaded.\n",
      "Loading collection 'document_chunks_flat' into memory for search...\n",
      "Collection 'document_chunks_flat' loaded.\n",
      "Attempting to load model from or download to: /Users/nitin/AgenticAI_Assignments/RAG_Assignment_1/downloaded_embedding_model/all-MiniLM-L12-v2\n",
      "Loading embedding model all-MiniLM-L12-v2 from local path '/Users/nitin/AgenticAI_Assignments/RAG_Assignment_1/downloaded_embedding_model/all-MiniLM-L12-v2'...\n",
      "Embedding model loaded successfully from local path.\n",
      "\n",
      "--- Starting Interactive RAG Pipeline (with Evaluation, Re-ranking & JSON Output) ---\n",
      "Enter 'exit' to quit.\n",
      "\n",
      "Performing retrieval for query: 'Your analysis on the roads for time period 2004-2007'\n",
      "Retrieved 20 relevant chunks from 'document_chunks_hnsw' in 0.0052 seconds.\n",
      "Retrieved 20 relevant chunks from 'document_chunks_ivf' in 0.0024 seconds.\n",
      "Retrieved 20 relevant chunks from 'document_chunks_flat' in 0.0029 seconds.\n",
      "\n",
      "--- Retrieval Performance Comparison ---\n",
      "  HNSW Retrieval Time: 0.0052 seconds\n",
      "    Top 5 Similarity (Distance): [0.4049, 0.3783, 0.3662, 0.3654, 0.3651]\n",
      "  IVF_FLAT Retrieval Time: 0.0024 seconds\n",
      "    Top 5 Similarity (Distance): [0.4049, 0.3783, 0.3662, 0.3654, 0.3651]\n",
      "  FLAT Retrieval Time: 0.0029 seconds\n",
      "    Top 5 Similarity (Distance): [0.4049, 0.3783, 0.3662, 0.3654, 0.3651]\n",
      "\n",
      "--- Detailed Search Results ---\n",
      "\n",
      "--- Search Results (HNSW Index) ---\n",
      "HNSW Result 1 (Distance: 0.4049):\n",
      "  the annual PMIS pavement evaluation cycle, which begins in September of each fiscal year and \n",
      "usually lasts until February.  The percentage of lane miles rated influences the expected \n",
      "reliability of the reported “Good or better” value — higher percentages of  lane miles rated are \n",
      "expected to be more reliable than lower percentages. \n",
      "Table 7.17 shows the percentage of lane miles (mainlanes and frontage roads) rated for fiscal \n",
      "years 2004 through 2005. \n",
      "Table 7.17 — Total Lane Miles Rated, FY 2004-2005. \n",
      "Fiscal Year\n",
      "2004 2005\n",
      "Lane Miles Lane Miles\n",
      "District Rated Total\n",
      "Percent\n",
      "Rated Rated Total\n",
      "Percent\n",
      "Rated\n",
      "Abilene 8,309.6 8,428.8 98.59% 8,405.2 8,435.0 99.65%\n",
      "Amarillo 9,131.1 9,370.7 97.44% 8,886.8 9,369.7 94.85%\n",
      "Atlanta 6,088.8 6,451.7 94.38% 6,244.0 6,453.1 96.76%\n",
      "Austin 8,344.3 8,746.3 95.40% 8,276.1 8,771.4 94.35%\n",
      "Beaumont 5,374.9 5,690.1 94.46% 5,563.3 5,728.9 97.11%\n",
      "Brownwood 5,776.4 5,827.6 99.12% 5,771.8 5,834.6 98.92%\n",
      "Bryan 6,751.5 6,992.5 96.55% 6,743.9 7,001.3 96.32%\n",
      "HNSW Result 2 (Distance: 0.3783):\n",
      "  Figure 8.3 — US Pavement Needs, FY 2004-2007. ..................................................................\n",
      "208 \n",
      "Figure 8.4 — SH Pavement Needs, FY 2004-2007. ..................................................................\n",
      "209 \n",
      "Figure 8.5 — FM Pavement Needs, FY 2004-2007................................................................... 210\n",
      " \n",
      "Figure 8.6 — Flexible Pavement Needs, FY 2004-2007. ..........................................................\n",
      "211 \n",
      "Figure 8.7 — CRCP Pavement Needs, FY 2004-2007.\n",
      ".............................................................212 \n",
      "Figure 8.8 — JCP Pavement Needs, FY 2004-2007. .................................................................\n",
      "213 \n",
      "Figure 8.9 — Distribution of Lane Mile Needs, FY 2006-2007. ...............................................223 \n",
      "Figure 8.10 — Distribution of Funding Needs, FY 2006-2007.\n",
      "..................................................223\n",
      "viii  Condition of Texas Pavements, FY 2004-2007 \n",
      "List of Maps\n",
      "HNSW Result 3 (Distance: 0.3662):\n",
      "  Map 7.1 — Percentage of Lane Miles Above Pavement Condition Goal, FY 2006.\n",
      "................184\n",
      "Condition of Texas Pavements, FY 2004-2007  ix \n",
      "Map 7.2 — Percentage of Lane Miles Above Pavement Condition Goal, FY 2007................. 185 \n",
      "Map 8.1 — Preventive Maintenance Needs, FY 2006. .............................................................216 \n",
      "Map 8.2\n",
      " — Preventive Maintenance Needs, FY 2007. .............................................................217 \n",
      "Map 8.3\n",
      " — Rehabilitation Needs, FY 2006. .............................................................................220 \n",
      "Map 8.4\n",
      " — Rehabilitation Needs, FY 2007. .............................................................................221 \n",
      "Map 9.1\n",
      " — Location of Texas Counties.................................................................................... 228 \n",
      "Map 9.2 — Location of TxDOT Districts.\n",
      "................................................................................230\n",
      "HNSW Result 4 (Distance: 0.3654):\n",
      "  between 1 and 94 inches per mile. \n",
      "56.80 percent of the mainlane NHS lane miles had IRI between 1 and  94 in FY 2007. \n",
      "Table 7.16 — Percentage of NHS Lane Miles With IRI Less Than 95, FY 2004-2007. \n",
      " \n",
      "This is not the same as the “Good” smoothness measure shown in Table 7.19, which is based on \n",
      "IRI 1-95 and vehicle miles traveled. \n",
      "Fiscal Year\n",
      "District 2004 2005 2006 2007\n",
      "Abilene 63.79% 55.79% 62.40% 65.22%\n",
      "Amarillo 62.67% 57.77% 53.15% 61.21%\n",
      "Atlanta 89.62% 87.74% 88.66% 84.19%\n",
      "Austin 74.08% 73.35% 71.38% 57.70%\n",
      "Beaumont 44.67% 37.10% 42.19% 53.29%\n",
      "Brownwood 77.18% 73.15% 70.88% 71.19%\n",
      "Bryan 85.28% 80.88% 79.06% 79.83%\n",
      "Childress 88.83% 86.96% 85.37% 86.80%\n",
      "Corpus Christi 69.69% 68.05% 70.54% 64.94%\n",
      "Dallas 30.04% 32.93% 28.47% 32.09%\n",
      "El Paso 47.03% 34.96% 30.35% 39.56%\n",
      "Fort Worth 28.90% 31.58% 29.62% 30.82%\n",
      "Houston 32.85% 31.68% 32.55% 30.83%\n",
      "Laredo 55.07% 52.45% 50.96% 43.68%\n",
      "Lubbock 78.33% 69.61% 71.95% 72.98%\n",
      "Lufkin 65.87% 57.29% 50.82% 51.05%\n",
      "Odessa 73.79% 73.99% 71.35% 78.72%\n",
      "HNSW Result 5 (Distance: 0.3651):\n",
      "  Condition of Texas Pavements, FY 2004-2007 Chapter 7 191 \n",
      "Table 7.9 shows the percentage of lane miles considered to be in need of rehabilitation, based on \n",
      "the PMIS Ride Score, for fiscal years 2004 through 2007.  It includes all mainlanes and frontage \n",
      "roads with a Ride Score of 1.9 or below. \n",
      "Table 7.9 — Percentage of Lane Miles With Ride Score 0.1-1.9, FY 2004-2007. \n",
      " \n",
      " \n",
      "Fiscal Year\n",
      "District 2004 2005 2006 2007\n",
      "Abilene 2.03% 2.88% 2.88% 2.45%\n",
      "Amarillo 1.30% 1.66% 1.40% 0.80%\n",
      "Atlanta 0.41% 0.38% 0.34% 0.69%\n",
      "Austin 0.26% 0.16% 0.31% 0.64%\n",
      "Beaumont 1.33% 2.07% 2.27% 1.48%\n",
      "Brownwood 0.33% 0.45% 0.82% 0.68%\n",
      "Bryan 2.47% 3.49% 4.11% 3.64%\n",
      "Childress 0.48% 0.47% 0.52% 0.36%\n",
      "Corpus Christi 3.04% 4.76% 4.43% 6.95%\n",
      "Dallas 2.78% 2.97% 4.43% 4.12%\n",
      "El Paso 5.02% 7.50% 8.65% 5.47%\n",
      "Fort Worth 1.97% 1.38% 1.50% 1.48%\n",
      "Houston 1.15% 1.36% 1.79% 1.54%\n",
      "Laredo 5.04% 5.23% 5.89% 6.65%\n",
      "Lubbock 0.38% 0.74% 0.85% 0.66%\n",
      "Lufkin 3.19% 3.40% 2.89% 2.73%\n",
      "Odessa 1.10% 0.78% 0.88% 0.92%\n",
      "\n",
      "--- Search Results (IVF_FLAT Index) ---\n",
      "IVF_FLAT Result 1 (Distance: 0.4049):\n",
      "  the annual PMIS pavement evaluation cycle, which begins in September of each fiscal year and \n",
      "usually lasts until February.  The percentage of lane miles rated influences the expected \n",
      "reliability of the reported “Good or better” value — higher percentages of  lane miles rated are \n",
      "expected to be more reliable than lower percentages. \n",
      "Table 7.17 shows the percentage of lane miles (mainlanes and frontage roads) rated for fiscal \n",
      "years 2004 through 2005. \n",
      "Table 7.17 — Total Lane Miles Rated, FY 2004-2005. \n",
      "Fiscal Year\n",
      "2004 2005\n",
      "Lane Miles Lane Miles\n",
      "District Rated Total\n",
      "Percent\n",
      "Rated Rated Total\n",
      "Percent\n",
      "Rated\n",
      "Abilene 8,309.6 8,428.8 98.59% 8,405.2 8,435.0 99.65%\n",
      "Amarillo 9,131.1 9,370.7 97.44% 8,886.8 9,369.7 94.85%\n",
      "Atlanta 6,088.8 6,451.7 94.38% 6,244.0 6,453.1 96.76%\n",
      "Austin 8,344.3 8,746.3 95.40% 8,276.1 8,771.4 94.35%\n",
      "Beaumont 5,374.9 5,690.1 94.46% 5,563.3 5,728.9 97.11%\n",
      "Brownwood 5,776.4 5,827.6 99.12% 5,771.8 5,834.6 98.92%\n",
      "Bryan 6,751.5 6,992.5 96.55% 6,743.9 7,001.3 96.32%\n",
      "IVF_FLAT Result 2 (Distance: 0.3783):\n",
      "  Figure 8.3 — US Pavement Needs, FY 2004-2007. ..................................................................\n",
      "208 \n",
      "Figure 8.4 — SH Pavement Needs, FY 2004-2007. ..................................................................\n",
      "209 \n",
      "Figure 8.5 — FM Pavement Needs, FY 2004-2007................................................................... 210\n",
      " \n",
      "Figure 8.6 — Flexible Pavement Needs, FY 2004-2007. ..........................................................\n",
      "211 \n",
      "Figure 8.7 — CRCP Pavement Needs, FY 2004-2007.\n",
      ".............................................................212 \n",
      "Figure 8.8 — JCP Pavement Needs, FY 2004-2007. .................................................................\n",
      "213 \n",
      "Figure 8.9 — Distribution of Lane Mile Needs, FY 2006-2007. ...............................................223 \n",
      "Figure 8.10 — Distribution of Funding Needs, FY 2006-2007.\n",
      "..................................................223\n",
      "viii  Condition of Texas Pavements, FY 2004-2007 \n",
      "List of Maps\n",
      "IVF_FLAT Result 3 (Distance: 0.3662):\n",
      "  Map 7.1 — Percentage of Lane Miles Above Pavement Condition Goal, FY 2006.\n",
      "................184\n",
      "Condition of Texas Pavements, FY 2004-2007  ix \n",
      "Map 7.2 — Percentage of Lane Miles Above Pavement Condition Goal, FY 2007................. 185 \n",
      "Map 8.1 — Preventive Maintenance Needs, FY 2006. .............................................................216 \n",
      "Map 8.2\n",
      " — Preventive Maintenance Needs, FY 2007. .............................................................217 \n",
      "Map 8.3\n",
      " — Rehabilitation Needs, FY 2006. .............................................................................220 \n",
      "Map 8.4\n",
      " — Rehabilitation Needs, FY 2007. .............................................................................221 \n",
      "Map 9.1\n",
      " — Location of Texas Counties.................................................................................... 228 \n",
      "Map 9.2 — Location of TxDOT Districts.\n",
      "................................................................................230\n",
      "IVF_FLAT Result 4 (Distance: 0.3654):\n",
      "  between 1 and 94 inches per mile. \n",
      "56.80 percent of the mainlane NHS lane miles had IRI between 1 and  94 in FY 2007. \n",
      "Table 7.16 — Percentage of NHS Lane Miles With IRI Less Than 95, FY 2004-2007. \n",
      " \n",
      "This is not the same as the “Good” smoothness measure shown in Table 7.19, which is based on \n",
      "IRI 1-95 and vehicle miles traveled. \n",
      "Fiscal Year\n",
      "District 2004 2005 2006 2007\n",
      "Abilene 63.79% 55.79% 62.40% 65.22%\n",
      "Amarillo 62.67% 57.77% 53.15% 61.21%\n",
      "Atlanta 89.62% 87.74% 88.66% 84.19%\n",
      "Austin 74.08% 73.35% 71.38% 57.70%\n",
      "Beaumont 44.67% 37.10% 42.19% 53.29%\n",
      "Brownwood 77.18% 73.15% 70.88% 71.19%\n",
      "Bryan 85.28% 80.88% 79.06% 79.83%\n",
      "Childress 88.83% 86.96% 85.37% 86.80%\n",
      "Corpus Christi 69.69% 68.05% 70.54% 64.94%\n",
      "Dallas 30.04% 32.93% 28.47% 32.09%\n",
      "El Paso 47.03% 34.96% 30.35% 39.56%\n",
      "Fort Worth 28.90% 31.58% 29.62% 30.82%\n",
      "Houston 32.85% 31.68% 32.55% 30.83%\n",
      "Laredo 55.07% 52.45% 50.96% 43.68%\n",
      "Lubbock 78.33% 69.61% 71.95% 72.98%\n",
      "Lufkin 65.87% 57.29% 50.82% 51.05%\n",
      "Odessa 73.79% 73.99% 71.35% 78.72%\n",
      "IVF_FLAT Result 5 (Distance: 0.3651):\n",
      "  Condition of Texas Pavements, FY 2004-2007 Chapter 7 191 \n",
      "Table 7.9 shows the percentage of lane miles considered to be in need of rehabilitation, based on \n",
      "the PMIS Ride Score, for fiscal years 2004 through 2007.  It includes all mainlanes and frontage \n",
      "roads with a Ride Score of 1.9 or below. \n",
      "Table 7.9 — Percentage of Lane Miles With Ride Score 0.1-1.9, FY 2004-2007. \n",
      " \n",
      " \n",
      "Fiscal Year\n",
      "District 2004 2005 2006 2007\n",
      "Abilene 2.03% 2.88% 2.88% 2.45%\n",
      "Amarillo 1.30% 1.66% 1.40% 0.80%\n",
      "Atlanta 0.41% 0.38% 0.34% 0.69%\n",
      "Austin 0.26% 0.16% 0.31% 0.64%\n",
      "Beaumont 1.33% 2.07% 2.27% 1.48%\n",
      "Brownwood 0.33% 0.45% 0.82% 0.68%\n",
      "Bryan 2.47% 3.49% 4.11% 3.64%\n",
      "Childress 0.48% 0.47% 0.52% 0.36%\n",
      "Corpus Christi 3.04% 4.76% 4.43% 6.95%\n",
      "Dallas 2.78% 2.97% 4.43% 4.12%\n",
      "El Paso 5.02% 7.50% 8.65% 5.47%\n",
      "Fort Worth 1.97% 1.38% 1.50% 1.48%\n",
      "Houston 1.15% 1.36% 1.79% 1.54%\n",
      "Laredo 5.04% 5.23% 5.89% 6.65%\n",
      "Lubbock 0.38% 0.74% 0.85% 0.66%\n",
      "Lufkin 3.19% 3.40% 2.89% 2.73%\n",
      "Odessa 1.10% 0.78% 0.88% 0.92%\n",
      "\n",
      "--- Search Results (FLAT Index) ---\n",
      "FLAT Result 1 (Distance: 0.4049):\n",
      "  the annual PMIS pavement evaluation cycle, which begins in September of each fiscal year and \n",
      "usually lasts until February.  The percentage of lane miles rated influences the expected \n",
      "reliability of the reported “Good or better” value — higher percentages of  lane miles rated are \n",
      "expected to be more reliable than lower percentages. \n",
      "Table 7.17 shows the percentage of lane miles (mainlanes and frontage roads) rated for fiscal \n",
      "years 2004 through 2005. \n",
      "Table 7.17 — Total Lane Miles Rated, FY 2004-2005. \n",
      "Fiscal Year\n",
      "2004 2005\n",
      "Lane Miles Lane Miles\n",
      "District Rated Total\n",
      "Percent\n",
      "Rated Rated Total\n",
      "Percent\n",
      "Rated\n",
      "Abilene 8,309.6 8,428.8 98.59% 8,405.2 8,435.0 99.65%\n",
      "Amarillo 9,131.1 9,370.7 97.44% 8,886.8 9,369.7 94.85%\n",
      "Atlanta 6,088.8 6,451.7 94.38% 6,244.0 6,453.1 96.76%\n",
      "Austin 8,344.3 8,746.3 95.40% 8,276.1 8,771.4 94.35%\n",
      "Beaumont 5,374.9 5,690.1 94.46% 5,563.3 5,728.9 97.11%\n",
      "Brownwood 5,776.4 5,827.6 99.12% 5,771.8 5,834.6 98.92%\n",
      "Bryan 6,751.5 6,992.5 96.55% 6,743.9 7,001.3 96.32%\n",
      "FLAT Result 2 (Distance: 0.3783):\n",
      "  Figure 8.3 — US Pavement Needs, FY 2004-2007. ..................................................................\n",
      "208 \n",
      "Figure 8.4 — SH Pavement Needs, FY 2004-2007. ..................................................................\n",
      "209 \n",
      "Figure 8.5 — FM Pavement Needs, FY 2004-2007................................................................... 210\n",
      " \n",
      "Figure 8.6 — Flexible Pavement Needs, FY 2004-2007. ..........................................................\n",
      "211 \n",
      "Figure 8.7 — CRCP Pavement Needs, FY 2004-2007.\n",
      ".............................................................212 \n",
      "Figure 8.8 — JCP Pavement Needs, FY 2004-2007. .................................................................\n",
      "213 \n",
      "Figure 8.9 — Distribution of Lane Mile Needs, FY 2006-2007. ...............................................223 \n",
      "Figure 8.10 — Distribution of Funding Needs, FY 2006-2007.\n",
      "..................................................223\n",
      "viii  Condition of Texas Pavements, FY 2004-2007 \n",
      "List of Maps\n",
      "FLAT Result 3 (Distance: 0.3662):\n",
      "  Map 7.1 — Percentage of Lane Miles Above Pavement Condition Goal, FY 2006.\n",
      "................184\n",
      "Condition of Texas Pavements, FY 2004-2007  ix \n",
      "Map 7.2 — Percentage of Lane Miles Above Pavement Condition Goal, FY 2007................. 185 \n",
      "Map 8.1 — Preventive Maintenance Needs, FY 2006. .............................................................216 \n",
      "Map 8.2\n",
      " — Preventive Maintenance Needs, FY 2007. .............................................................217 \n",
      "Map 8.3\n",
      " — Rehabilitation Needs, FY 2006. .............................................................................220 \n",
      "Map 8.4\n",
      " — Rehabilitation Needs, FY 2007. .............................................................................221 \n",
      "Map 9.1\n",
      " — Location of Texas Counties.................................................................................... 228 \n",
      "Map 9.2 — Location of TxDOT Districts.\n",
      "................................................................................230\n",
      "FLAT Result 4 (Distance: 0.3654):\n",
      "  between 1 and 94 inches per mile. \n",
      "56.80 percent of the mainlane NHS lane miles had IRI between 1 and  94 in FY 2007. \n",
      "Table 7.16 — Percentage of NHS Lane Miles With IRI Less Than 95, FY 2004-2007. \n",
      " \n",
      "This is not the same as the “Good” smoothness measure shown in Table 7.19, which is based on \n",
      "IRI 1-95 and vehicle miles traveled. \n",
      "Fiscal Year\n",
      "District 2004 2005 2006 2007\n",
      "Abilene 63.79% 55.79% 62.40% 65.22%\n",
      "Amarillo 62.67% 57.77% 53.15% 61.21%\n",
      "Atlanta 89.62% 87.74% 88.66% 84.19%\n",
      "Austin 74.08% 73.35% 71.38% 57.70%\n",
      "Beaumont 44.67% 37.10% 42.19% 53.29%\n",
      "Brownwood 77.18% 73.15% 70.88% 71.19%\n",
      "Bryan 85.28% 80.88% 79.06% 79.83%\n",
      "Childress 88.83% 86.96% 85.37% 86.80%\n",
      "Corpus Christi 69.69% 68.05% 70.54% 64.94%\n",
      "Dallas 30.04% 32.93% 28.47% 32.09%\n",
      "El Paso 47.03% 34.96% 30.35% 39.56%\n",
      "Fort Worth 28.90% 31.58% 29.62% 30.82%\n",
      "Houston 32.85% 31.68% 32.55% 30.83%\n",
      "Laredo 55.07% 52.45% 50.96% 43.68%\n",
      "Lubbock 78.33% 69.61% 71.95% 72.98%\n",
      "Lufkin 65.87% 57.29% 50.82% 51.05%\n",
      "Odessa 73.79% 73.99% 71.35% 78.72%\n",
      "FLAT Result 5 (Distance: 0.3651):\n",
      "  Condition of Texas Pavements, FY 2004-2007 Chapter 7 191 \n",
      "Table 7.9 shows the percentage of lane miles considered to be in need of rehabilitation, based on \n",
      "the PMIS Ride Score, for fiscal years 2004 through 2007.  It includes all mainlanes and frontage \n",
      "roads with a Ride Score of 1.9 or below. \n",
      "Table 7.9 — Percentage of Lane Miles With Ride Score 0.1-1.9, FY 2004-2007. \n",
      " \n",
      " \n",
      "Fiscal Year\n",
      "District 2004 2005 2006 2007\n",
      "Abilene 2.03% 2.88% 2.88% 2.45%\n",
      "Amarillo 1.30% 1.66% 1.40% 0.80%\n",
      "Atlanta 0.41% 0.38% 0.34% 0.69%\n",
      "Austin 0.26% 0.16% 0.31% 0.64%\n",
      "Beaumont 1.33% 2.07% 2.27% 1.48%\n",
      "Brownwood 0.33% 0.45% 0.82% 0.68%\n",
      "Bryan 2.47% 3.49% 4.11% 3.64%\n",
      "Childress 0.48% 0.47% 0.52% 0.36%\n",
      "Corpus Christi 3.04% 4.76% 4.43% 6.95%\n",
      "Dallas 2.78% 2.97% 4.43% 4.12%\n",
      "El Paso 5.02% 7.50% 8.65% 5.47%\n",
      "Fort Worth 1.97% 1.38% 1.50% 1.48%\n",
      "Houston 1.15% 1.36% 1.79% 1.54%\n",
      "Laredo 5.04% 5.23% 5.89% 6.65%\n",
      "Lubbock 0.38% 0.74% 0.85% 0.66%\n",
      "Lufkin 3.19% 3.40% 2.89% 2.73%\n",
      "Odessa 1.10% 0.78% 0.88% 0.92%\n",
      "\n",
      "--- Applying Re-ranking and Generating LLM Response ---\n",
      "Re-ranked 5 chunks using MMR.\n",
      "Generating LLM response...\n",
      "\n",
      "Sending request to Gemini LLM...\n",
      "\n",
      "--- Final RAG Response ---\n",
      "Query: Your analysis on the roads for time period 2004-2007\n",
      "\n",
      "Retrieved & Re-ranked Context (sent to LLM):\n",
      "  Rank 1 (Distance: 0.3368): measures and adjusts funding, as necessary, to improve the overall condition of Texas \n",
      "pavements.  These performance measures are then used for TxDOT pavement management, for \n",
      "funding of pavement projects in the annual Unified Transportation Program (UTP), and for \n",
      "National strategic planning. \n",
      "Performance Measures Analyzed in This Chapter \n",
      "This chapter reports the FY 2004-2007 PMIS data in terms of the following performance \n",
      "measures: \n",
      "♦ Statewide Pavement Condition Goal – Percentage of Lane Miles in “Good” or Better \n",
      "Condition \n",
      "♦ UTP Category 1 — Preventive Maintenance and Rehabilitation \n",
      "♦ FHWA Strategic Goal for NHS Ride Quality. \n",
      " \n",
      "Overview of the Statewide Pavement Condition Goal \n",
      "In August 2001, the Texas Transportation Commission set a goal to have 90 percent of Texas \n",
      "pavement lane miles in “Good” or better condition within the next ten years (that is, by FY \n",
      "2012).  “Good or better” was defined as a PMIS Condition Score of 70 or above.  In July 2002,\n",
      "  Rank 2 (Distance: 0.3501): 121 \n",
      "Chapter 5  Condition of Rigid Pavements — JCP....................................................................... 137 \n",
      "Chapter 6  Maintenance Level of Service\n",
      "...................................................................................153 \n",
      "Chapter 7  Performa\n",
      "nce Measures\n",
      "...............................................................................................179 \n",
      "Chapter 8 Estimate of Pavement Needs\n",
      ".....................................................................................205 \n",
      "Chapter 9  Summary....................................................................................................................227\n",
      "vi  Condition of Texas Pavements, FY 2004-2007 \n",
      "List of Figures \n",
      "Figure 1.1 — Average PMIS Scores (with Ride), FY 2004-2007. ................................................ 2 \n",
      "Figure 1.2 — Average PMIS Scores (with IRI), FY 2004-2007....................................................3 \n",
      "Figure 1.3 — Conditio\n",
      "  Rank 3 (Distance: 0.3375): at 1 percent. \n",
      "“Low-traffic” roads accounted for 26.90 percent of the lane miles but only 1.62 percent of the \n",
      "vehicles miles traveled in FY 2007. Both of these percentages decreased in FY 2007. \n",
      "“Medium-traffic” roads also got worse in FY 2007, and showed exactly the same trends as the \n",
      "“Low-traffic” roads.  “Desirable” mileage dropped by ten percent, “Acceptable” mileage rose by \n",
      "seven percent, “Tolerable” mileage rose by three percent, and “Intolerable” mileage stayed the \n",
      "same at 1 percent. \n",
      "“Medium-traffic” roads accounted for 59.21 percent of the lane miles and 42.13 percent of the \n",
      "vehicles miles traveled in FY 2007.  The percentage of lane miles increased, but the percentage \n",
      "of vehicle miles traveled decreased in FY 2007. \n",
      "“High-traffic” roads stayed the same overall in FY 2007.  A seven percent drop in “Desirable” \n",
      "mileage was matched by a seven percent rise in “Acceptable” mileage, and a one percent drop in\n",
      "  Rank 4 (Distance: 0.3635): /168/167/52/53\n",
      "/168/167/52/53\n",
      "/168/167/49/48/168/167/49/48\n",
      "/168/167\n",
      "/54/49/48\n",
      "/72/111/117/115/116 /111/110\n",
      "Condition of Texas Pavements, FY 2004-2007 Chapter 2 57 \n",
      "Map 2.8— IH System Ride Score Classes, FY 2007. \n",
      " \n",
      " \n",
      "/168/167/49/48\n",
      "/168/167/49/48\n",
      "/168/167/51/55\n",
      "/168/167/52/53\n",
      "/168/167/51/48/168/167/51/53\n",
      "/168/167/51/53\n",
      "/168/167/51/53\n",
      "/168/167/50/48\n",
      "/168/167/49/48\n",
      "/168/167/50/48\n",
      "/168/167/49/48\n",
      "/168/167/50/55\n",
      "/168/167/52/52\n",
      "/168/167/52/48\n",
      "/82/105 /100/101/32 /83/99/111/114/101/32/67/108/97/115/115/101/115\n",
      "/52/46/48/32/45/32/53/46/48\n",
      "/51/46/48/32/45/32/51/46/57\n",
      "/50/46/48/32/45/32/50/46/57\n",
      "/49/46/48/32/45/32/49/46/57\n",
      "/48/46/49/32/45/32/48/46/57\n",
      "/78/111/32/68/97/116/97\n",
      "/168/167/52/53\n",
      "/168/167/50/48\n",
      "/168/167/51/48\n",
      "/168/167\n",
      "/51/53/69\n",
      "/168/167\n",
      "/51/53/87\n",
      "/168/167\n",
      "/51/53/87\n",
      "/168/167\n",
      "/54/51/53\n",
      "/168/167/56 /50/48\n",
      "/68/97/108/108/97/115/47/70/111/114/116/32/87 /111/114/116/104\n",
      "/168/167/51/53\n",
      "/168/167/49/48\n",
      "/168/167/51/55\n",
      "/168/167/49/48\n",
      "/168/167\n",
      "/52/49/48\n",
      "  Rank 5 (Distance: 0.3510): 0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "“Desirable” “Acceptable” “Tolerable” “Intolerable”\n",
      "Level of Service\n",
      "Lane Miles, Percent\n",
      "2004 2005 2006 2007\n",
      "Condition of Texas Pavements, FY 2004-2007 Chapter 6 157 \n",
      "Maps 6.1 and 6.2 on the following pages show Rutting level of service in each county for fiscal \n",
      "years 2006 and 2007.  These maps show the percentage of lane miles in each county that were \n",
      "maintained at a “Desirable” or “Acceptable” level of service.  Counties in red had the lowest \n",
      "Rutting level of service, while counties in blue had the highest Rutting level of service. \n",
      "The percentage of lane miles with “Desirable” or “Acceptable” level of service for Rutting \n",
      "decreased in FY 2007.  The amount of Shallow Rutting and Deep Rutting increased, as described \n",
      "in Chapter 3. \n",
      "Rutting increased even after subtracting 0.1 inches from each rut depth measurement.  This was \n",
      "done to compensate for a change in the Rutbar dynamic calibration procedure back in FY 2006\n",
      "\n",
      "Answer: For the time period of FY 2004-2007, the PMIS data was reported in terms of:\n",
      "\n",
      "*   Statewide Pavement Condition Goal – Percentage of Lane Miles in “Good” or Better Condition\n",
      "*   UTP Category 1 — Preventive Maintenance and Rehabilitation\n",
      "*   FHWA Strategic Goal for NHS Ride Quality.\n",
      "--------------------\n",
      "\n",
      "RAG output saved to JSON for DOCX generation: rag_output_1749222990.json\n",
      "\n",
      "Step 5 (RAG LLM Generation with JSON Output) completed. Now, run the DOCX generation script.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time # Import time for measuring performance\n",
    "from pymilvus import connections, utility, Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Any\n",
    "from huggingface_hub import snapshot_download\n",
    "import requests # For making API calls to Gemini\n",
    "import numpy as np # For numerical operations in MMR\n",
    "\n",
    "\n",
    "# --- Configuration for Milvus Connection ---\n",
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "COLLECTION_NAME = \"document_chunks\"\n",
    "\n",
    "# --- Embedding Model Configuration ---\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L12-v2\"\n",
    "VECTOR_DIMENSION = 384\n",
    "\n",
    "embedding_model = None\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
    "\n",
    "def connect_to_milvus():\n",
    "    try:\n",
    "        print(f\"Attempting to connect to Milvus at {MILVUS_HOST}:{MILVUS_PORT}...\")\n",
    "        connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "        utility.list_collections()\n",
    "        print(\"Milvus connection successful!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Milvus connection failed: {e}\")\n",
    "        print(\"Please ensure your Milvus Docker container is running (run 'docker ps').\")\n",
    "        return False\n",
    "\n",
    "def get_embedding_model():\n",
    "    global embedding_model\n",
    "    if embedding_model is None:\n",
    "        local_model_dir = os.path.join(os.getcwd(), \"downloaded_embedding_model\", EMBEDDING_MODEL_NAME.replace(\"/\", \"--\"))\n",
    "        os.makedirs(local_model_dir, exist_ok=True)\n",
    "        print(f\"Attempting to load model from or download to: {local_model_dir}\")\n",
    "\n",
    "        # Check for existence of crucial files\n",
    "        config_file_exists = os.path.exists(os.path.join(local_model_dir, \"config.json\"))\n",
    "        pytorch_model_file_exists = os.path.exists(os.path.join(local_model_dir, \"pytorch_model.bin\"))\n",
    "\n",
    "        model_is_downloaded_and_intact = config_file_exists and pytorch_model_file_exists\n",
    "\n",
    "        if not model_is_downloaded_and_intact:\n",
    "            print(f\"Model files not found or incomplete in '{local_model_dir}'. Initiating robust download...\")\n",
    "            try:\n",
    "                # Use snapshot_download to get all model files\n",
    "                snapshot_download(\n",
    "                    repo_id=f\"sentence-transformers/{EMBEDDING_MODEL_NAME}\",\n",
    "                    local_dir=local_model_dir,\n",
    "                    local_dir_use_symlinks=False, # Copy files directly, don't use symlinks\n",
    "                    resume_download=True # Allow resuming interrupted downloads\n",
    "                )\n",
    "                print(f\"Model successfully downloaded to: {local_model_dir}\")\n",
    "                # Re-check existence after download\n",
    "                model_is_downloaded_and_intact = os.path.exists(os.path.join(local_model_dir, \"config.json\")) and \\\n",
    "                                                  os.path.exists(os.path.join(local_model_dir, \"pytorch_model.bin\"))\n",
    "                if not model_is_downloaded_and_intact:\n",
    "                    print(f\"WARNING: Download completed, but essential files (config.json or pytorch_model.bin) are still missing in '{local_model_dir}'.\")\n",
    "                    print(\"This might indicate a problem with the downloaded archive or disk permissions.\")\n",
    "                    return None # Critical files missing even after download\n",
    "            except Exception as download_e:\n",
    "                print(f\"Error during model download to '{local_model_dir}': {download_e}\")\n",
    "                print(\"Please check your internet connection, disk space, and permissions for the download directory.\")\n",
    "                return None # Return None if download fails\n",
    "\n",
    "        if model_is_downloaded_and_intact:\n",
    "            try:\n",
    "                print(f\"Loading embedding model {EMBEDDING_MODEL_NAME} from local path '{local_model_dir}'...\")\n",
    "                # Now that we are sure the files are local, use local_files_only=True\n",
    "                embedding_model = SentenceTransformer(local_model_dir, model_kwargs={'device': 'cpu'}, local_files_only=True)\n",
    "                print(\"Embedding model loaded successfully from local path.\")\n",
    "            except Exception as load_e:\n",
    "                print(f\"Error loading embedding model {EMBEDDING_MODEL_NAME} from local path '{local_model_dir}': {load_e}\")\n",
    "                print(\"This could be due to corrupted files or a compatibility issue.\")\n",
    "                print(f\"Please try deleting the model cache folder '{local_model_dir}' and re-running the script to force a fresh download.\")\n",
    "                embedding_model = None\n",
    "        else:\n",
    "            print(\"Model was not downloaded or is incomplete. Cannot load embedding model.\")\n",
    "            embedding_model = None # Ensure it's None if download failed or files incomplete\n",
    "\n",
    "    return embedding_model\n",
    "\n",
    "def get_milvus_collection(collection_suffix: str) -> Collection:\n",
    "    full_collection_name = f\"{COLLECTION_NAME}_{collection_suffix}\"\n",
    "    if not utility.has_collection(full_collection_name):\n",
    "        print(f\"Error: Collection '{full_collection_name}' does not exist.\")\n",
    "        print(\"Please run milvus_full_setup_ingestion.py first to create and populate collections.\")\n",
    "        return None\n",
    "    collection = Collection(full_collection_name)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading collection '{collection.name}' into memory for search...\")\n",
    "        collection.load()\n",
    "        print(f\"Collection '{collection.name}' loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading collection '{collection.name}': {e}\")\n",
    "        return None\n",
    "            \n",
    "    return collection\n",
    "\n",
    "def retrieve_relevant_chunks(query_text: str, collection: Collection, top_k: int = 3) -> List[Dict[str, Any]]:\n",
    "    if not collection:\n",
    "        print(f\"Collection '{collection.name if collection else 'unknown'}' not available for search.\")\n",
    "        return [], 0 # Return empty list and 0 time on error\n",
    "\n",
    "    model = get_embedding_model()\n",
    "    if not model:\n",
    "        print(\"Embedding model not loaded. Cannot embed query.\")\n",
    "        return [], 0 # Return empty list and 0 time on error\n",
    "\n",
    "    query_embedding = model.encode(query_text).tolist()\n",
    "\n",
    "    search_params = {\n",
    "        \"data\": [query_embedding],\n",
    "        \"anns_field\": \"embedding\",\n",
    "        \"limit\": top_k,\n",
    "        \"output_fields\": [\"page_content\", \"embedding\"], # Request embeddings for MMR\n",
    "        \"expr\": \"pk > 0\"\n",
    "    }\n",
    "\n",
    "    if \"hnsw\" in collection.name:\n",
    "        search_params[\"param\"] = {\"metric_type\": \"COSINE\", \"params\": {\"ef\": 64}}\n",
    "    elif \"ivf\" in collection.name:\n",
    "        search_params[\"param\"] = {\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}}\n",
    "    elif \"flat\" in collection.name:\n",
    "        search_params[\"param\"] = {\"metric_type\": \"COSINE\", \"params\": {}}\n",
    "\n",
    "    search_start_time = time.time()\n",
    "    try:\n",
    "        results = collection.search(**search_params)\n",
    "        search_end_time = time.time()\n",
    "        search_time = search_end_time - search_start_time\n",
    "\n",
    "        retrieved_chunks = []\n",
    "        for hit in results[0]:\n",
    "            retrieved_chunks.append({\n",
    "                \"page_content\": hit.entity.get(\"page_content\"),\n",
    "                \"embedding\": hit.entity.get(\"embedding\"), # Get embedding for MMR\n",
    "                \"distance\": hit.distance\n",
    "            })\n",
    "        \n",
    "        print(f\"Retrieved {len(retrieved_chunks)} relevant chunks from '{collection.name}' in {search_time:.4f} seconds.\")\n",
    "        return retrieved_chunks, search_time\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search in '{collection.name}': {e}\")\n",
    "        return [], 0 # Return empty list and 0 time on error\n",
    "\n",
    "def calculate_mmr(query_embedding: np.ndarray, documents: List[Dict[str, Any]], lambda_mult: float = 0.5, k: int = 5) -> List[Dict[str, Any]]:\n",
    "    if not documents:\n",
    "        return []\n",
    "\n",
    "    # Ensure embeddings are numpy arrays\n",
    "    doc_embeddings = np.array([doc['embedding'] for doc in documents])\n",
    "    \n",
    "    # Calculate initial relevance scores (already provided as distance, but normalize for consistency if needed)\n",
    "    # Since cosine similarity is used, lower distance means higher similarity. We can use 1 - distance as a score.\n",
    "    relevance_scores = np.array([1 - doc['distance'] for doc in documents])\n",
    "\n",
    "    # Calculate pairwise similarity between all documents\n",
    "    # Using dot product for cosine similarity with normalized vectors (which SentenceTransformer provides)\n",
    "    document_similarity = np.dot(doc_embeddings, doc_embeddings.T)\n",
    "    # Ensure diagonal is 0 or low to avoid self-similarity impacting selection\n",
    "    np.fill_diagonal(document_similarity, -1) # Set diagonal to -1 to avoid picking same document\n",
    "\n",
    "    selected_indices = []\n",
    "    unselected_indices = list(range(len(documents)))\n",
    "\n",
    "    for _ in range(min(k, len(documents))):\n",
    "        if not unselected_indices:\n",
    "            break\n",
    "\n",
    "        mmr_scores = []\n",
    "        for idx in unselected_indices:\n",
    "            # Relevance part\n",
    "            relevance = relevance_scores[idx]\n",
    "\n",
    "            # Diversity part (max similarity to already selected documents)\n",
    "            if selected_indices:\n",
    "                diversity = np.max(document_similarity[idx, selected_indices])\n",
    "            else:\n",
    "                diversity = 0 # No selected documents yet, so no diversity penalty\n",
    "\n",
    "            # MMR score\n",
    "            mmr_score = lambda_mult * relevance - (1 - lambda_mult) * diversity\n",
    "            mmr_scores.append((mmr_score, idx))\n",
    "\n",
    "        # Select the document with the highest MMR score\n",
    "        best_idx_in_unselected = max(mmr_scores, key=lambda x: x[0])[1]\n",
    "        selected_indices.append(best_idx_in_unselected)\n",
    "        unselected_indices.remove(best_idx_in_unselected)\n",
    "\n",
    "    re_ranked_documents = [documents[i] for i in selected_indices]\n",
    "    return re_ranked_documents\n",
    "\n",
    "\n",
    "def generate_llm_response(query: str, context_chunks: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Generates a response from the LLM using the provided query and context.\n",
    "    \"\"\"\n",
    "    if not context_chunks:\n",
    "        print(\"No context chunks provided for LLM. Generating response without context.\")\n",
    "        context_str = \"No relevant context available.\"\n",
    "    else:\n",
    "        context_str = \"\\n\".join([f\"Chunk {i+1}: {chunk}\" for i, chunk in enumerate(context_chunks)])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant specialized in answering questions based on provided information.\n",
    "    Answer the user's query truthfully and concisely, using ONLY the context provided below.\n",
    "    If the answer cannot be found in the context, state that you don't have enough information.\n",
    "\n",
    "    User Query: {query}\n",
    "\n",
    "    Context:\n",
    "    {context_str}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    chat_history = []\n",
    "    chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": prompt}]})\n",
    "\n",
    "    payload = {\"contents\": chat_history}\n",
    "    \n",
    "    api_key_param = f\"?key={GEMINI_API_KEY}\" if GEMINI_API_KEY else \"\"\n",
    "    api_url_with_key = f\"{GEMINI_API_URL}{api_key_param}\"\n",
    "\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    print(\"\\nSending request to Gemini LLM...\")\n",
    "    try:\n",
    "        response = requests.post(api_url_with_key, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "\n",
    "        if result.get(\"candidates\") and result[\"candidates\"][0].get(\"content\") and result[\"candidates\"][0][\"content\"].get(\"parts\"):\n",
    "            llm_response = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "            return llm_response\n",
    "        else:\n",
    "            print(f\"Unexpected API response format: {result}\")\n",
    "            return \"Could not generate a response from the LLM due to an unexpected API format.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during Gemini API call: {e}\")\n",
    "        return \"An error occurred while communicating with the LLM API.\"\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during LLM response generation: {e}\")\n",
    "        return \"An unexpected error occurred during LLM response generation.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import pymilvus\n",
    "        import json\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        from huggingface_hub import snapshot_download\n",
    "        import requests\n",
    "        import numpy as np\n",
    "    except ImportError as e:\n",
    "        print(f\"Missing required library: {e}. Please install using:\")\n",
    "        print(\"pip install pymilvus sentence-transformers huggingface-hub requests numpy\")\n",
    "        exit()\n",
    "\n",
    "    # Connect to Milvus\n",
    "    if not connect_to_milvus():\n",
    "        exit()\n",
    "\n",
    "    # Get Milvus Collections\n",
    "    print(\"\\n--- Retrieving Milvus Collections ---\")\n",
    "    hnsw_collection = get_milvus_collection(\"hnsw\")\n",
    "    ivf_collection = get_milvus_collection(\"ivf\")\n",
    "    flat_collection = get_milvus_collection(\"flat\")\n",
    "    \n",
    "    if not all([hnsw_collection, ivf_collection, flat_collection]):\n",
    "        print(\"Not all required Milvus collections are available or loaded. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Get Embedding Model\n",
    "    model = get_embedding_model()\n",
    "    if not model:\n",
    "        print(\"Failed to load embedding model. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Interactive RAG Loop with Evaluation, Re-ranking, and JSON Output for DOCX\n",
    "    print(\"\\n--- Starting Interactive RAG Pipeline (with Evaluation, Re-ranking & JSON Output) ---\")\n",
    "    print(\"Enter 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nEnter your query: \")\n",
    "        if user_query.lower() == 'exit':\n",
    "            break\n",
    "\n",
    "        # Store results for comparison\n",
    "        all_retrieval_results = {}\n",
    "\n",
    "        # --- Perform retrieval for each index type ---\n",
    "        print(f\"\\nPerforming retrieval for query: '{user_query}'\")\n",
    "        \n",
    "        # HNSW Search\n",
    "        hnsw_retrieved_chunks, hnsw_time = retrieve_relevant_chunks(user_query, hnsw_collection, top_k=20) # Get more for re-ranking\n",
    "        all_retrieval_results[\"HNSW\"] = {\"chunks\": hnsw_retrieved_chunks, \"time\": hnsw_time}\n",
    "\n",
    "        # IVF_FLAT Search\n",
    "        ivf_retrieved_chunks, ivf_time = retrieve_relevant_chunks(user_query, ivf_collection, top_k=20)\n",
    "        all_retrieval_results[\"IVF_FLAT\"] = {\"chunks\": ivf_retrieved_chunks, \"time\": ivf_time}\n",
    "        \n",
    "        # FLAT Search\n",
    "        flat_retrieved_chunks, flat_time = retrieve_relevant_chunks(user_query, flat_collection, top_k=20)\n",
    "        all_retrieval_results[\"FLAT\"] = {\"chunks\": flat_retrieved_chunks, \"time\": flat_time}\n",
    "\n",
    "        print(\"\\n--- Retrieval Performance Comparison ---\")\n",
    "        for index_type, data in all_retrieval_results.items():\n",
    "            print(f\"  {index_type} Retrieval Time: {data['time']:.4f} seconds\")\n",
    "            if data[\"chunks\"]:\n",
    "                top_5_distances_str = \", \".join([f'{c[\"distance\"]:.4f}' for c in data['chunks'][:5]])\n",
    "                print(f\"    Top 5 Similarity (Distance): [{top_5_distances_str}]\")\n",
    "            else:\n",
    "                print(\"    No chunks retrieved.\")\n",
    "\n",
    "        # --- Display detailed search results for each index type ---\n",
    "        print(\"\\n--- Detailed Search Results ---\")\n",
    "\n",
    "        print(\"\\n--- Search Results (HNSW Index) ---\")\n",
    "        current_hnsw_chunks = all_retrieval_results[\"HNSW\"][\"chunks\"]\n",
    "        if current_hnsw_chunks:\n",
    "            for i, chunk in enumerate(current_hnsw_chunks[:5]):\n",
    "                print(f\"HNSW Result {i+1} (Distance: {chunk['distance']:.4f}):\")\n",
    "                print(f\"  {chunk['page_content'].strip()}\")\n",
    "        else:\n",
    "            print(\"No results found from HNSW index.\")\n",
    "\n",
    "        print(\"\\n--- Search Results (IVF_FLAT Index) ---\")\n",
    "        current_ivf_chunks = all_retrieval_results[\"IVF_FLAT\"][\"chunks\"]\n",
    "        if current_ivf_chunks:\n",
    "            for i, chunk in enumerate(current_ivf_chunks[:5]):\n",
    "                print(f\"IVF_FLAT Result {i+1} (Distance: {chunk['distance']:.4f}):\")\n",
    "                print(f\"  {chunk['page_content'].strip()}\")\n",
    "        else:\n",
    "            print(\"No results found from IVF_FLAT index.\")\n",
    "        \n",
    "        print(\"\\n--- Search Results (FLAT Index) ---\")\n",
    "        current_flat_chunks = all_retrieval_results[\"FLAT\"][\"chunks\"]\n",
    "        if current_flat_chunks:\n",
    "            for i, chunk in enumerate(current_flat_chunks[:5]):\n",
    "                print(f\"FLAT Result {i+1} (Distance: {chunk['distance']:.4f}):\")\n",
    "                print(f\"  {chunk['page_content'].strip()}\")\n",
    "        else:\n",
    "            print(\"No results found from FLAT index.\")\n",
    "\n",
    "\n",
    "        # --- Re-ranking and LLM Generation (using HNSW results for simplicity) ---\n",
    "        print(\"\\n--- Applying Re-ranking and Generating LLM Response ---\")\n",
    "        query_embedding_np = model.encode(user_query).astype(np.float32) if model else np.array([])\n",
    "        \n",
    "        if hnsw_retrieved_chunks and query_embedding_np.size > 0:\n",
    "            re_ranked_chunks = calculate_mmr(\n",
    "                query_embedding_np,\n",
    "                hnsw_retrieved_chunks,\n",
    "                lambda_mult=0.7,\n",
    "                k=5\n",
    "            )\n",
    "            print(f\"Re-ranked {len(re_ranked_chunks)} chunks using MMR.\")\n",
    "            context_for_llm = [chunk['page_content'] for chunk in re_ranked_chunks]\n",
    "        else:\n",
    "            re_ranked_chunks = []\n",
    "            context_for_llm = []\n",
    "            print(\"No chunks retrieved from HNSW for re-ranking or query embedding failed.\")\n",
    "\n",
    "        # Generate LLM response\n",
    "        print(\"Generating LLM response...\")\n",
    "        llm_answer = generate_llm_response(user_query, context_for_llm)\n",
    "\n",
    "        print(\"\\n--- Final RAG Response ---\")\n",
    "        print(f\"Query: {user_query}\")\n",
    "        print(\"\\nRetrieved & Re-ranked Context (sent to LLM):\")\n",
    "        if re_ranked_chunks:\n",
    "            for i, chunk in enumerate(re_ranked_chunks):\n",
    "                print(f\"  Rank {i+1} (Distance: {chunk['distance']:.4f}): {chunk['page_content'].strip()}\")\n",
    "        else:\n",
    "            print(\"  No relevant context retrieved or re-ranked.\")\n",
    "        print(f\"\\nAnswer: {llm_answer}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "        # --- Save RAG output to JSON for DOCX generation ---\n",
    "        output_data = {\n",
    "            \"query\": user_query,\n",
    "            \"retrieved_context\": context_for_llm,\n",
    "            \"llm_answer\": llm_answer\n",
    "        }\n",
    "        json_output_filename = f\"rag_output_{int(time.time())}.json\"\n",
    "        try:\n",
    "            with open(json_output_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(output_data, f, indent=2)\n",
    "            print(f\"\\nRAG output saved to JSON for DOCX generation: {json_output_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving RAG output to JSON: {e}\")\n",
    "\n",
    "\n",
    "    print(\"\\nStep 5 (RAG LLM Generation with JSON Output) completed. Now, run the DOCX generation script.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3235667",
   "metadata": {},
   "source": [
    "# STEP 7 -- DOCX REPORT GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0fdc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from: rag_output_1749222990.json\n",
      "\n",
      "DOCX report saved to: RAG_Report_1749222990.docx\n",
      "\n",
      "DOCX Generation completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from typing import List\n",
    "\n",
    "def generate_docx_report(query: str, retrieved_context: List[str], llm_answer: str, output_filename: str = \"rag_report.docx\"):\n",
    "    \"\"\"\n",
    "    Generates a DOCX report containing the user query, retrieved context, and LLM answer.\n",
    "    \"\"\"\n",
    "    doc = Document()\n",
    "    doc.add_heading('RAG System Report', level=1)\n",
    "\n",
    "    doc.add_heading('1. User Query', level=2)\n",
    "    doc.add_paragraph(query)\n",
    "\n",
    "    doc.add_heading('2. Retrieved and Re-ranked Context', level=2)\n",
    "    if retrieved_context:\n",
    "        for i, chunk in enumerate(retrieved_context):\n",
    "            doc.add_paragraph(f\"Chunk {i+1}: {chunk.strip()}\")\n",
    "    else:\n",
    "        doc.add_paragraph(\"No relevant context was retrieved or re-ranked for this query.\")\n",
    "\n",
    "    doc.add_heading('3. LLM Generated Answer', level=2)\n",
    "    doc.add_paragraph(llm_answer)\n",
    "\n",
    "    try:\n",
    "        doc.save(output_filename)\n",
    "        print(f\"\\nDOCX report saved to: {output_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving DOCX report: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    json_file_path = \"rag_output_1749222990.json\"\n",
    "\n",
    "    # Ensure necessary libraries are installed (this block remains for local execution safety)\n",
    "    try:\n",
    "        from docx import Document\n",
    "        from docx.shared import Inches\n",
    "        import json, os\n",
    "    except ImportError as e:\n",
    "        print(f\"Missing required library: {e}. Please install using:\")\n",
    "        print(\"pip install python-docx\")\n",
    "        print(\"Please install the missing library to proceed.\")\n",
    "        raise RuntimeError(\"Required library not installed\")\n",
    "\n",
    "    if not os.path.exists(json_file_path):\n",
    "        print(f\"Error: JSON input file '{json_file_path}' not found.\")\n",
    "        print(\"Please ensure the path is correct and the JSON file was generated by the RAG pipeline.\")\n",
    "        raise FileNotFoundError(f\"JSON input file '{json_file_path}' not found.\")\n",
    "    else:\n",
    "        output_data = {}\n",
    "        try:\n",
    "            with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "                output_data = json.load(f)\n",
    "            print(f\"Successfully loaded data from: {json_file_path}\")\n",
    "\n",
    "            query_from_json = output_data.get(\"query\", \"N/A\")\n",
    "            context_from_json = output_data.get(\"retrieved_context\", [])\n",
    "            answer_from_json = output_data.get(\"llm_answer\", \"No answer generated.\")\n",
    "\n",
    "            # Generate a unique DOCX filename based on the JSON file's timestamp or a new one\n",
    "            base_filename = os.path.basename(json_file_path)\n",
    "            # Remove \"rag_output_\" and \".json\" to get the timestamp for the DOCX filename\n",
    "            timestamp_part = base_filename.replace(\"rag_output_\", \"\").replace(\".json\", \"\")\n",
    "            docx_output_filename = f\"RAG_Report_{timestamp_part}.docx\"\n",
    "\n",
    "            generate_docx_report(query_from_json, context_from_json, answer_from_json, docx_output_filename)\n",
    "            print(\"\\nDOCX Generation completed.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading JSON data from '{json_file_path}' or generating DOCX: {e}\")\n",
    "            raise\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGAssignment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
